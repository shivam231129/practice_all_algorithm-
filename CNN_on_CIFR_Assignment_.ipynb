{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kK3alCdFflQX"
   },
   "source": [
    "### CNN on CIFR Assignment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHCYMwwXflQd"
   },
   "source": [
    "1.  Please visit this link to access the state-of-art DenseNet code for reference - DenseNet - cifar10 notebook link\n",
    "2.  You need to create a copy of this and \"retrain\" this model to achieve 90+ test accuracy. \n",
    "3.  You cannot use Dense Layers (also called fully connected layers), or DropOut.\n",
    "4.  You MUST use Image Augmentation Techniques.\n",
    "5.  You cannot use an already trained model as a beginning points, you have to initilize as your own\n",
    "6.  You cannot run the program for more than 300 Epochs, and it should be clear from your log, that you have only used 300 Epochs\n",
    "7.  You cannot use test images for training the model.\n",
    "8.  You cannot change the general architecture of DenseNet (which means you must use Dense Block, Transition and Output blocks as mentioned in the code)\n",
    "9.  You are free to change Convolution types (e.g. from 3x3 normal convolution to Depthwise Separable, etc)\n",
    "10. You cannot have more than 1 Million parameters in total\n",
    "11. You are free to move the code from Keras to Tensorflow, Pytorch, MXNET etc. \n",
    "12. You can use any optimization algorithm you need. \n",
    "13. You can checkpoint your model and retrain the model from that checkpoint so that no need of training the model from first if you lost at any epoch while training. You can directly load that model and Train from that epoch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TLVcyNYKflQi"
   },
   "outputs": [],
   "source": [
    " import keras\n",
    " from keras.datasets import cifar10\n",
    " from keras.models import Model, Sequential\n",
    " from keras.layers import Dense, Dropout, Flatten, Input, AveragePooling2D, merge, Activation\n",
    " from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    " from keras.layers import Concatenate\n",
    " from keras.optimizers import Adam\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ee4GwmZkZp4B"
   },
   "outputs": [],
   "source": [
    "# this part will prevent tensorflow to allocate all the avaliable GPU Memory\n",
    "# backend\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d3BrG7eNZvsZ"
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 10\n",
    "l = 8\n",
    "\n",
    "\n",
    "l = 8\n",
    "num_filter = 27\n",
    "#compression = 1\n",
    "compression =1\n",
    "dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhCOqXKWsIwr"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-2kXH1eshFD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4wq2IomZ0kj"
   },
   "outputs": [],
   "source": [
    "# Load CIFAR10 Data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "img_height, img_width, channel = X_train.shape[1],X_train.shape[2],X_train.shape[3]\n",
    "\n",
    "# convert to one hot encoing \n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jVnyauvqdy5G"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JmBpO49Gdz2f",
    "outputId": "6e7a7593-8672-4a51-f73f-3c678ba0f6e8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jDUScs5ehARR"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HaxasmXxsPFD"
   },
   "outputs": [],
   "source": [
    "#creating data for validation\n",
    "X_train, X_cv, y_train, y_cv = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "neu4sk4NZ-eT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "colab_type": "code",
    "id": "Dn-N9VgeoG1q",
    "outputId": "fd22ac82-f219-46a9-d45e-ae4c0a5e55db"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CkBT9einggrN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3mDYBaSuhc93"
   },
   "outputs": [],
   "source": [
    "# Dense Block\n",
    "def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    temp = input\n",
    "    for _ in range(l): \n",
    "        BatchNorm = layers.BatchNormalization()(temp)\n",
    "        relu = layers.Activation('relu')(BatchNorm)\n",
    "        Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "        #if dropout_rate>0:\n",
    "         #   Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "        concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "        \n",
    "        temp = concat\n",
    "        \n",
    "    return temp\n",
    "\n",
    "## transition Blosck\n",
    "def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "    #if dropout_rate>0:\n",
    "     #    Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "    avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "    return avg\n",
    "\n",
    "#output layer\n",
    "def output_layer(input):\n",
    "    global compression\n",
    "    BatchNorm = layers.BatchNormalization()(input)\n",
    "    relu = layers.Activation('relu')(BatchNorm)\n",
    "    AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "    flat = layers.Flatten()(AvgPooling)\n",
    "    output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gkUcuH-nhscs",
    "outputId": "8d345bf5-cff3-4213-f6d5-b4f67aae1385",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 32, 32, 27)   324         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 32, 32, 27)   108         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 32, 32, 27)   0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 27)   6561        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 32, 32, 54)   0           conv2d[0][0]                     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 32, 32, 54)   216         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 54)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 27)   13122       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 81)   0           concatenate[0][0]                \n",
      "                                                                 conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 81)   324         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 32, 32, 81)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 27)   19683       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 108)  0           concatenate_1[0][0]              \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 32, 108)  432         concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 32, 108)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 27)   26244       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 135)  0           concatenate_2[0][0]              \n",
      "                                                                 conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 135)  540         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 135)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 32, 27)   32805       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 32, 32, 162)  0           concatenate_3[0][0]              \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 162)  648         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 162)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 27)   39366       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 189)  0           concatenate_4[0][0]              \n",
      "                                                                 conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 189)  756         concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 32, 32, 189)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 27)   45927       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 216)  0           concatenate_5[0][0]              \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 216)  864         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 32, 32, 216)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 27)   52488       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 32, 32, 243)  0           concatenate_6[0][0]              \n",
      "                                                                 conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 243)  972         concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 32, 32, 243)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 27)   6561        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 16, 16, 27)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 27)   108         average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 16, 16, 27)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 27)   6561        activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 16, 16, 54)   0           average_pooling2d[0][0]          \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 54)   216         concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 16, 16, 54)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 27)   13122       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 81)   0           concatenate_8[0][0]              \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 81)   324         concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 16, 16, 81)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 27)   19683       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16, 16, 108)  0           concatenate_9[0][0]              \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 108)  432         concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16, 16, 108)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 16, 16, 27)   26244       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 16, 16, 135)  0           concatenate_10[0][0]             \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 16, 16, 135)  540         concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 16, 16, 135)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 27)   32805       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 16, 16, 162)  0           concatenate_11[0][0]             \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 162)  648         concatenate_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 162)  0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 27)   39366       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 16, 16, 189)  0           concatenate_12[0][0]             \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 189)  756         concatenate_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 16, 16, 189)  0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 27)   45927       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 16, 16, 216)  0           concatenate_13[0][0]             \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 216)  864         concatenate_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 16, 16, 216)  0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 27)   52488       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 16, 16, 243)  0           concatenate_14[0][0]             \n",
      "                                                                 conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 243)  972         concatenate_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 16, 16, 243)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 27)   6561        activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 8, 8, 27)     0           conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 8, 8, 27)     108         average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 8, 8, 27)     0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 8, 8, 27)     6561        activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 8, 8, 54)     0           average_pooling2d_1[0][0]        \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 8, 8, 54)     216         concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 8, 8, 54)     0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 27)     13122       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 8, 8, 81)     0           concatenate_16[0][0]             \n",
      "                                                                 conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 81)     324         concatenate_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 8, 8, 81)     0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 27)     19683       activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 8, 8, 108)    0           concatenate_17[0][0]             \n",
      "                                                                 conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 108)    432         concatenate_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 8, 8, 108)    0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 27)     26244       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 8, 8, 135)    0           concatenate_18[0][0]             \n",
      "                                                                 conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 8, 8, 135)    540         concatenate_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 8, 8, 135)    0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 27)     32805       activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 8, 8, 162)    0           concatenate_19[0][0]             \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 8, 8, 162)    648         concatenate_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 8, 8, 162)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 8, 8, 27)     39366       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 8, 8, 189)    0           concatenate_20[0][0]             \n",
      "                                                                 conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 8, 8, 189)    756         concatenate_21[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 8, 8, 189)    0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 8, 8, 27)     45927       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 8, 8, 216)    0           concatenate_21[0][0]             \n",
      "                                                                 conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 8, 8, 216)    864         concatenate_22[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 8, 8, 216)    0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 8, 8, 27)     52488       activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 8, 8, 243)    0           concatenate_22[0][0]             \n",
      "                                                                 conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 8, 8, 243)    972         concatenate_23[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 8, 8, 243)    0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 8, 8, 27)     6561        activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 4, 4, 27)     0           conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 4, 4, 27)     108         average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 4, 4, 27)     0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 4, 4, 27)     6561        activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 4, 4, 54)     0           average_pooling2d_2[0][0]        \n",
      "                                                                 conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 4, 4, 54)     216         concatenate_24[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 4, 4, 54)     0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 4, 4, 27)     13122       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 4, 4, 81)     0           concatenate_24[0][0]             \n",
      "                                                                 conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 4, 4, 81)     324         concatenate_25[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 4, 4, 81)     0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 4, 4, 27)     19683       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 4, 4, 108)    0           concatenate_25[0][0]             \n",
      "                                                                 conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 4, 4, 108)    432         concatenate_26[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 4, 4, 108)    0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 4, 4, 27)     26244       activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 4, 4, 135)    0           concatenate_26[0][0]             \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 4, 4, 135)    540         concatenate_27[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 4, 4, 135)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 4, 4, 27)     32805       activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 4, 4, 162)    0           concatenate_27[0][0]             \n",
      "                                                                 conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 4, 4, 162)    648         concatenate_28[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 4, 4, 162)    0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 4, 4, 27)     39366       activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 4, 4, 189)    0           concatenate_28[0][0]             \n",
      "                                                                 conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 4, 4, 189)    756         concatenate_29[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 4, 4, 189)    0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 4, 4, 27)     45927       activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 4, 4, 216)    0           concatenate_29[0][0]             \n",
      "                                                                 conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 4, 4, 216)    864         concatenate_30[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 4, 4, 216)    0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 4, 4, 27)     52488       activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 4, 4, 243)    0           concatenate_30[0][0]             \n",
      "                                                                 conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 4, 4, 243)    972         concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 4, 4, 243)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 2, 2, 243)    0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 972)          0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 10)           9730        flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#num_filter = 36\n",
    "#dropout_rate = 0.2\n",
    "#l = 12\n",
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (2,2), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)\n",
    "\n",
    "base_model = Model(inputs=[input], outputs=[output])\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vE3aCRBfhyiC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fX-VcxCnWBkD",
    "outputId": "66077d31-c32d-4169-d1ee-ac6a8018b357"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 10)"
      ]
     },
     "execution_count": 189,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "yeuPwf4JfduB",
    "outputId": "1bd5cb0d-bd78-4b84-81c4-856b4f5299e8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_47\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 32, 32, 35)   420         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 32, 32, 35)   140         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 32, 32, 35)   0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 32, 32, 35)   11025       activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_264 (Concatenate)   (None, 32, 32, 70)   0           conv2d_319[0][0]                 \n",
      "                                                                 conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 32, 32, 70)   280         concatenate_264[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 32, 32, 70)   0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 32, 32, 35)   22050       activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_265 (Concatenate)   (None, 32, 32, 105)  0           concatenate_264[0][0]            \n",
      "                                                                 conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 32, 32, 105)  420         concatenate_265[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 32, 32, 105)  0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 32, 32, 35)   33075       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_266 (Concatenate)   (None, 32, 32, 140)  0           concatenate_265[0][0]            \n",
      "                                                                 conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 32, 32, 140)  560         concatenate_266[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 32, 32, 140)  0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 32, 32, 35)   44100       activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_267 (Concatenate)   (None, 32, 32, 175)  0           concatenate_266[0][0]            \n",
      "                                                                 conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 32, 32, 175)  700         concatenate_267[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 32, 32, 175)  0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 32, 32, 35)   55125       activation_312[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_268 (Concatenate)   (None, 32, 32, 210)  0           concatenate_267[0][0]            \n",
      "                                                                 conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 32, 32, 210)  840         concatenate_268[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 32, 32, 210)  0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 32, 32, 35)   66150       activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_269 (Concatenate)   (None, 32, 32, 245)  0           concatenate_268[0][0]            \n",
      "                                                                 conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 32, 32, 245)  980         concatenate_269[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 32, 32, 245)  0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 32, 32, 35)   8575        activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_44 (AveragePo (None, 16, 16, 35)   0           conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 16, 16, 35)   140         average_pooling2d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 16, 16, 35)   0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 16, 16, 35)   11025       activation_315[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_270 (Concatenate)   (None, 16, 16, 70)   0           average_pooling2d_44[0][0]       \n",
      "                                                                 conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 16, 16, 70)   280         concatenate_270[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 16, 16, 70)   0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 16, 16, 35)   22050       activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_271 (Concatenate)   (None, 16, 16, 105)  0           concatenate_270[0][0]            \n",
      "                                                                 conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 16, 16, 105)  420         concatenate_271[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 16, 16, 105)  0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 16, 16, 35)   33075       activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_272 (Concatenate)   (None, 16, 16, 140)  0           concatenate_271[0][0]            \n",
      "                                                                 conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 16, 16, 140)  560         concatenate_272[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 16, 16, 140)  0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 16, 16, 35)   44100       activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_273 (Concatenate)   (None, 16, 16, 175)  0           concatenate_272[0][0]            \n",
      "                                                                 conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 16, 16, 175)  700         concatenate_273[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 16, 16, 175)  0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 16, 16, 35)   55125       activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_274 (Concatenate)   (None, 16, 16, 210)  0           concatenate_273[0][0]            \n",
      "                                                                 conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 16, 16, 210)  840         concatenate_274[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 16, 16, 210)  0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 16, 16, 35)   66150       activation_320[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_275 (Concatenate)   (None, 16, 16, 245)  0           concatenate_274[0][0]            \n",
      "                                                                 conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 16, 16, 245)  980         concatenate_275[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 16, 16, 245)  0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 16, 16, 35)   8575        activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_45 (AveragePo (None, 8, 8, 35)     0           conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 8, 8, 35)     140         average_pooling2d_45[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 8, 8, 35)     0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 8, 8, 35)     11025       activation_322[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_276 (Concatenate)   (None, 8, 8, 70)     0           average_pooling2d_45[0][0]       \n",
      "                                                                 conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 8, 8, 70)     280         concatenate_276[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 8, 8, 70)     0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 8, 8, 35)     22050       activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_277 (Concatenate)   (None, 8, 8, 105)    0           concatenate_276[0][0]            \n",
      "                                                                 conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 8, 8, 105)    420         concatenate_277[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 8, 8, 105)    0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 8, 8, 35)     33075       activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_278 (Concatenate)   (None, 8, 8, 140)    0           concatenate_277[0][0]            \n",
      "                                                                 conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 8, 8, 140)    560         concatenate_278[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 8, 8, 140)    0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 8, 8, 35)     44100       activation_325[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_279 (Concatenate)   (None, 8, 8, 175)    0           concatenate_278[0][0]            \n",
      "                                                                 conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 8, 8, 175)    700         concatenate_279[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 8, 8, 175)    0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 8, 8, 35)     55125       activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_280 (Concatenate)   (None, 8, 8, 210)    0           concatenate_279[0][0]            \n",
      "                                                                 conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 8, 8, 210)    840         concatenate_280[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 8, 8, 210)    0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 8, 8, 35)     66150       activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_281 (Concatenate)   (None, 8, 8, 245)    0           concatenate_280[0][0]            \n",
      "                                                                 conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 8, 8, 245)    980         concatenate_281[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 8, 8, 245)    0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 8, 8, 35)     8575        activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_46 (AveragePo (None, 4, 4, 35)     0           conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 4, 4, 35)     140         average_pooling2d_46[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 4, 4, 35)     0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 4, 4, 35)     11025       activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_282 (Concatenate)   (None, 4, 4, 70)     0           average_pooling2d_46[0][0]       \n",
      "                                                                 conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 4, 4, 70)     280         concatenate_282[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 4, 4, 70)     0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 4, 4, 35)     22050       activation_330[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_283 (Concatenate)   (None, 4, 4, 105)    0           concatenate_282[0][0]            \n",
      "                                                                 conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 4, 4, 105)    420         concatenate_283[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 4, 4, 105)    0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 4, 4, 35)     33075       activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_284 (Concatenate)   (None, 4, 4, 140)    0           concatenate_283[0][0]            \n",
      "                                                                 conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 4, 4, 140)    560         concatenate_284[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 4, 4, 140)    0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 4, 4, 35)     44100       activation_332[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_285 (Concatenate)   (None, 4, 4, 175)    0           concatenate_284[0][0]            \n",
      "                                                                 conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 4, 4, 175)    700         concatenate_285[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 4, 4, 175)    0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 4, 4, 35)     55125       activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_286 (Concatenate)   (None, 4, 4, 210)    0           concatenate_285[0][0]            \n",
      "                                                                 conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 4, 4, 210)    840         concatenate_286[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 4, 4, 210)    0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 4, 4, 35)     66150       activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_287 (Concatenate)   (None, 4, 4, 245)    0           concatenate_286[0][0]            \n",
      "                                                                 conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 4, 4, 245)    980         concatenate_287[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 4, 4, 245)    0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_47 (AveragePo (None, 2, 2, 245)    0           activation_335[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 967,925\n",
      "Trainable params: 960,085\n",
      "Non-trainable params: 7,840\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#removing the last dense layes with flatten\n",
    "base_model.layers.pop()\n",
    "model2 = Model(base_model.input, base_model.layers[-3].output)\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "atppb-8PdFK-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UfbkOwp0ri_i",
    "outputId": "453deafd-97b9-4c31-c93b-bb5755d9ee1f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'average_pooling2d_47/AvgPool:0' shape=(None, 2, 2, 245) dtype=float32>]"
      ]
     },
     "execution_count": 191,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "0x6GkXTgJq67",
    "outputId": "2ef344d2-c652-4284-a04f-a86b54183798"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_47 (Functional)   (None, 2, 2, 245)         967925    \n",
      "_________________________________________________________________\n",
      "conv2d_347 (Conv2D)          (None, 1, 1, 10)          9810      \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 977,735\n",
      "Trainable params: 969,895\n",
      "Non-trainable params: 7,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#adding a con layer at last \n",
    "model = models.Sequential()\n",
    "model.add(model2)\n",
    "model.add(layers.Conv2D(10,(2,2),strides=[1,1],padding='valid',activation='softmax'))\n",
    "model.add(layers.Flatten())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zmeKIpq5qvLk",
    "outputId": "0f4339f2-3a04-4ad3-a5da-6baf23629381"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 2, 2, 245)"
      ]
     },
     "execution_count": 193,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " model2.output_shape\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eL2EbXTojftu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "id": "wIM7lVxiL1az",
    "outputId": "259c829c-1ec1-487a-a8ab-62632641c1bb",
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRE3Ky9SqYZY"
   },
   "outputs": [],
   "source": [
    "# early_stop = EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "def decay_fn(epoch, lr):\n",
    "    if epoch < 50:\n",
    "        return 0.001\n",
    "    elif epoch >= 50 and epoch < 75:\n",
    "        return 0.0001\n",
    "    else:\n",
    "        return 0.00001\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(decay_fn)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from keras.callbacks import *\n",
    "filepath=\"/content/gdrive/My Drive/MyCNN/epochs:{epoch:03d}-val_accuracy:{val_accuracy:.3f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.load_weights('/content/gdrive/My Drive/MyCNN/epochs:004-val_accuracy:0.753.hdf5')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "-lIDD2Xy9t84",
    "outputId": "f4bc80ea-3d01-4efa-ceab-765aa9fe1a1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_47 (Functional)   (None, 2, 2, 245)         967925    \n",
      "_________________________________________________________________\n",
      "conv2d_347 (Conv2D)          (None, 1, 1, 10)          9810      \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 977,735\n",
      "Trainable params: 969,895\n",
      "Non-trainable params: 7,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "8LziriSciUI8",
    "outputId": "79d2d785-c67d-403d-c244-228a0d6d090f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0175 - accuracy: 0.6435\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.62340, saving model to /content/gdrive/My Drive/MyCNN/epochs:001-val_accuracy:0.623.hdf5\n",
      "391/390 [==============================] - 132s 338ms/step - loss: 1.0175 - accuracy: 0.6435 - val_loss: 1.1844 - val_accuracy: 0.6234\n",
      "Epoch 2/10\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8754 - accuracy: 0.6932\n",
      "Epoch 00002: val_accuracy improved from 0.62340 to 0.68460, saving model to /content/gdrive/My Drive/MyCNN/epochs:002-val_accuracy:0.685.hdf5\n",
      "391/390 [==============================] - 129s 329ms/step - loss: 0.8754 - accuracy: 0.6932 - val_loss: 0.9796 - val_accuracy: 0.6846\n",
      "Epoch 3/10\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8004 - accuracy: 0.7213\n",
      "Epoch 00003: val_accuracy improved from 0.68460 to 0.71270, saving model to /content/gdrive/My Drive/MyCNN/epochs:003-val_accuracy:0.713.hdf5\n",
      "391/390 [==============================] - 129s 329ms/step - loss: 0.8004 - accuracy: 0.7213 - val_loss: 0.8710 - val_accuracy: 0.7127\n",
      "Epoch 4/10\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7452 - accuracy: 0.7405\n",
      "Epoch 00004: val_accuracy did not improve from 0.71270\n",
      "391/390 [==============================] - 128s 328ms/step - loss: 0.7452 - accuracy: 0.7405 - val_loss: 0.9037 - val_accuracy: 0.7064\n",
      "Epoch 5/10\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7002 - accuracy: 0.7573\n",
      "Epoch 00005: val_accuracy improved from 0.71270 to 0.73960, saving model to /content/gdrive/My Drive/MyCNN/epochs:005-val_accuracy:0.740.hdf5\n",
      "391/390 [==============================] - 129s 329ms/step - loss: 0.7002 - accuracy: 0.7573 - val_loss: 0.8318 - val_accuracy: 0.7396\n",
      "Epoch 6/10\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6624 - accuracy: 0.7688\n",
      "Epoch 00006: val_accuracy improved from 0.73960 to 0.79620, saving model to /content/gdrive/My Drive/MyCNN/epochs:006-val_accuracy:0.796.hdf5\n",
      "391/390 [==============================] - 129s 329ms/step - loss: 0.6624 - accuracy: 0.7688 - val_loss: 0.6004 - val_accuracy: 0.7962\n",
      "Epoch 7/10\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6309 - accuracy: 0.7806\n",
      "Epoch 00007: val_accuracy did not improve from 0.79620\n",
      "391/390 [==============================] - 128s 328ms/step - loss: 0.6309 - accuracy: 0.7806 - val_loss: 0.7625 - val_accuracy: 0.7527\n",
      "Epoch 8/10\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6003 - accuracy: 0.7913\n",
      "Epoch 00008: val_accuracy did not improve from 0.79620\n",
      "391/390 [==============================] - 128s 328ms/step - loss: 0.6003 - accuracy: 0.7913 - val_loss: 0.7666 - val_accuracy: 0.7568\n",
      "Epoch 9/10\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5746 - accuracy: 0.8010\n",
      "Epoch 00009: val_accuracy did not improve from 0.79620\n",
      "391/390 [==============================] - 128s 328ms/step - loss: 0.5746 - accuracy: 0.8010 - val_loss: 0.6197 - val_accuracy: 0.7935\n",
      "Epoch 10/10\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5552 - accuracy: 0.8070\n",
      "Epoch 00010: val_accuracy improved from 0.79620 to 0.80170, saving model to /content/gdrive/My Drive/MyCNN/epochs:010-val_accuracy:0.802.hdf5\n",
      "391/390 [==============================] - 129s 330ms/step - loss: 0.5552 - accuracy: 0.8070 - val_loss: 0.5779 - val_accuracy: 0.8017\n"
     ]
    }
   ],
   "source": [
    "# test on 10 epochs\n",
    "history= model.fit(datagen.flow(X_train, y_train, batch_size),\n",
    "        steps_per_epoch=len(X_train) / batch_size, epochs=10,validation_data=(X_cv, y_cv),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y2TaP4CcOPV7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMoTM2NrlX6S"
   },
   "outputs": [],
   "source": [
    "X_test=X_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "ZeUbtm0MjVdi",
    "outputId": "66301fa0-5614-4d43-ac96-a4ba66898c6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 0.7541 - accuracy: 0.7849\n",
      "Test loss: 0.7541395425796509\n",
      "Test accuracy: 0.7849000096321106\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGGhwNftwKV3"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
    "# https://stackoverflow.com/a/14434334\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "TNYevCsAlNs7",
    "outputId": "c0df3cdf-0697-4d14-af8d-1c8675edd5fa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,10+1))\n",
    "\n",
    "# print(history.history.keys())\n",
    "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
    "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\n",
    "\n",
    "# we will get val_loss and val_acc only when you pass the paramter validation_data\n",
    "# val_loss : validation loss\n",
    "# val_acc : validation accuracy\n",
    "\n",
    "# loss : training loss\n",
    "# acc : train accuracy\n",
    "# for each key in histrory.histrory we will have a list of length equal to number of epochs\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "C8oerCdMhOEC",
    "outputId": "a5408a22-65b4-4098-be97-f0ee47b80759"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f60ed8bde80>"
      ]
     },
     "execution_count": 125,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ArP033zZm-iA",
    "outputId": "410b27ce-6532-4fc9-cfff-f86df26c656c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 129
    },
    "colab_type": "code",
    "id": "G8OMptgY7Wsu",
    "outputId": "e38196a7-93b6-455b-a19c-abb81eb04654"
   },
   "source": [
    "### using image augumentation horizontal vertical shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fhPwP39LYhM5",
    "outputId": "2b724323-9702-46c3-9cfb-bf0cad65ddc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 126,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qMA9a0pcj2Ac"
   },
   "outputs": [],
   "source": [
    "# Reff https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "\n",
    "def vertical_horizontal_shift(arr_imgs):\n",
    "\n",
    "      # convert to numpy array\n",
    "      d_ar = arr_imgs.copy()\n",
    "      \n",
    "      for i in tqdm(range(d_ar.shape[0]), position=0):\n",
    "          data = d_ar[i]\n",
    "          # expand dimension to one sample\n",
    "          samples = np.expand_dims(data, 0)\n",
    "          # create image data augmentation generator\n",
    "          datagen = ImageDataGenerator(width_shift_range=[-15,15], height_shift_range=[-15,15])\n",
    "          # prepare iterator\n",
    "          it = datagen.flow(samples, batch_size=1)\n",
    "          # generate samples and plot\n",
    "          # define subplot\n",
    "          # pyplot.subplot(330 + 1 + i)\n",
    "          # generate batch of images\n",
    "          #for j in range(9):\n",
    "          batch = it.next()     \n",
    "              #if j == 0:\n",
    "\n",
    "                  # convert to unsigned integers for viewing\n",
    "          image = batch[0].astype('uint8')\n",
    "          d_ar[i] = image\n",
    "                  # plot raw pixel data\n",
    "                  #break\n",
    "      return d_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "nZ8IocLipnRK",
    "outputId": "473ed1e1-d23d-47a3-d86c-fe5bce460c57"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "N8zUGxAtqStl",
    "outputId": "f8b3f4c2-e5f3-4973-cf9f-747968edf05c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:35<00:00, 1422.15it/s]\n",
      "100%|██████████| 10000/10000 [00:06<00:00, 1435.51it/s]\n",
      "100%|██████████| 10000/10000 [00:07<00:00, 1425.08it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_hor_ver_shift=vertical_horizontal_shift(X_train)\n",
    "X_cv_hor_ver_shift=vertical_horizontal_shift(X_cv)\n",
    "X_test_hor_ver_shift=vertical_horizontal_shift(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R2sfPPRprxZM"
   },
   "outputs": [],
   "source": [
    "# function which activate network and replace last dense layer with conv layer\n",
    "def modell(X_train,X_cv,X_test,y_train,y_cv,y_test):        # Dense Block\n",
    "        def denseblock(input, num_filter = 12, dropout_rate = 0.2):\n",
    "          global compression\n",
    "          temp = input\n",
    "          for _ in range(l): \n",
    "              BatchNorm = layers.BatchNormalization()(temp)\n",
    "              relu = layers.Activation('relu')(BatchNorm)\n",
    "              Conv2D_3_3 = layers.Conv2D(int(num_filter*compression), (3,3), use_bias=False ,padding='same')(relu)\n",
    "              if dropout_rate>0:\n",
    "                  Conv2D_3_3 = layers.Dropout(dropout_rate)(Conv2D_3_3)\n",
    "              concat = layers.Concatenate(axis=-1)([temp,Conv2D_3_3])\n",
    "              \n",
    "              temp = concat\n",
    "              \n",
    "          return temp\n",
    "\n",
    "        ## transition Blosck\n",
    "        def transition(input, num_filter = 12, dropout_rate = 0.2):\n",
    "          global compression\n",
    "          BatchNorm = layers.BatchNormalization()(input)\n",
    "          relu = layers.Activation('relu')(BatchNorm)\n",
    "          Conv2D_BottleNeck = layers.Conv2D(int(num_filter*compression), (1,1), use_bias=False ,padding='same')(relu)\n",
    "          if dropout_rate>0:\n",
    "                Conv2D_BottleNeck = layers.Dropout(dropout_rate)(Conv2D_BottleNeck)\n",
    "          avg = layers.AveragePooling2D(pool_size=(2,2))(Conv2D_BottleNeck)\n",
    "          return avg\n",
    "\n",
    "        #output layer\n",
    "        def output_layer(input):\n",
    "          global compression\n",
    "          BatchNorm = layers.BatchNormalization()(input)\n",
    "          relu = layers.Activation('relu')(BatchNorm)\n",
    "          AvgPooling = layers.AveragePooling2D(pool_size=(2,2))(relu)\n",
    "          flat = layers.Flatten()(AvgPooling)\n",
    "          output = layers.Dense(num_classes, activation='softmax')(flat)\n",
    "          return output\n",
    "\n",
    "\n",
    "\n",
    "          #num_filter = 36\n",
    "        #dropout_rate = 0.2\n",
    "        #l = 12\n",
    "        input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "        First_Conv2D = layers.Conv2D(num_filter, (2,2), use_bias=False ,padding='same')(input)\n",
    "\n",
    "        First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "        First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "        Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "        Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "        Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "        Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "        Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "        output = output_layer(Last_Block)\n",
    "\n",
    "        base_model = Model(inputs=[input], outputs=[output])\n",
    "        base_model.summary()\n",
    "        print(\"^*\"*100)\n",
    "        print(\"*************************************after removing last dense layer******************************************\")\n",
    "        print(\"^*\"*100)\n",
    "        base_model.layers.pop()\n",
    "        model2 = Model(base_model.input, base_model.layers[-3].output)\n",
    "        model2.summary()\n",
    "\n",
    "        print(\"^*\"*100)\n",
    "        print(\"**************************************after adding conv2d layer****************************************\")\n",
    "\n",
    "        model = models.Sequential()\n",
    "        model.add(model2)\n",
    "        model.add(layers.Conv2D(10,(2,2),strides=[1,1],padding='valid',activation='softmax'))\n",
    "        model.add(layers.Flatten())\n",
    "        model.summary()\n",
    "        print(\"^*\"*100)\n",
    "        model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])\n",
    "        history= model.fit(X_train, y_train, batch_size,epochs=10,validation_data=(X_cv, y_cv))\n",
    "\n",
    "        score = model.evaluate(X_test, y_test, verbose=1)\n",
    "        print('Test loss:', score[0])\n",
    "        print('Test accuracy:', score[1])\n",
    "        return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9Nly30UWgw6"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "uj2PPcQ3tXS_",
    "outputId": "e57da3f4-1151-43c8-c633-ce4269299d94",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 27)   324         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 27)   108         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 27)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 27)   6561        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 27)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 32, 32, 54)   0           conv2d_36[0][0]                  \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 54)   216         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 54)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 27)   13122       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 27)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 32, 32, 81)   0           concatenate_32[0][0]             \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 81)   324         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 81)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 27)   19683       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 27)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 32, 32, 108)  0           concatenate_33[0][0]             \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 108)  432         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 108)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 27)   26244       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 27)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 32, 32, 135)  0           concatenate_34[0][0]             \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 32, 32, 135)  540         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 135)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 27)   32805       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 27)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 32, 32, 162)  0           concatenate_35[0][0]             \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 32, 32, 162)  648         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 32, 162)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 27)   39366       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 27)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 32, 32, 189)  0           concatenate_36[0][0]             \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32, 32, 189)  756         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 32, 32, 189)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 27)   45927       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 27)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 32, 32, 216)  0           concatenate_37[0][0]             \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 32, 32, 216)  864         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 32, 216)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 27)   52488       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 27)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 32, 32, 243)  0           concatenate_38[0][0]             \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 32, 32, 243)  972         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 32, 32, 243)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 27)   6561        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 27)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 16, 16, 27)   0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 27)   108         average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 27)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 27)   6561        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 27)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 16, 16, 54)   0           average_pooling2d_4[0][0]        \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 54)   216         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 54)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 27)   13122       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 16, 27)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 16, 16, 81)   0           concatenate_40[0][0]             \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 81)   324         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 81)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 27)   19683       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, 16, 27)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 16, 16, 108)  0           concatenate_41[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 108)  432         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 108)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 27)   26244       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 16, 27)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 16, 16, 135)  0           concatenate_42[0][0]             \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 135)  540         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 135)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 27)   32805       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 27)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 16, 16, 162)  0           concatenate_43[0][0]             \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 162)  648         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 162)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 27)   39366       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 27)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 16, 16, 189)  0           concatenate_44[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 189)  756         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 189)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 27)   45927       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 27)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 16, 16, 216)  0           concatenate_45[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 216)  864         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 216)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 27)   52488       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 27)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 16, 16, 243)  0           concatenate_46[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 243)  972         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 243)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 27)   6561        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 27)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 8, 8, 27)     0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 27)     108         average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 27)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 27)     6561        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 8, 8, 27)     0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 8, 8, 54)     0           average_pooling2d_5[0][0]        \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 54)     216         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 54)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 27)     13122       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 8, 8, 27)     0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 8, 8, 81)     0           concatenate_48[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 81)     324         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 81)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 27)     19683       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 8, 8, 27)     0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 8, 8, 108)    0           concatenate_49[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 108)    432         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 108)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 27)     26244       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 8, 8, 27)     0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 8, 8, 135)    0           concatenate_50[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 135)    540         concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 135)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 27)     32805       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 8, 8, 27)     0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 8, 8, 162)    0           concatenate_51[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 162)    648         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 162)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 27)     39366       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 8, 8, 27)     0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 8, 8, 189)    0           concatenate_52[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 189)    756         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 189)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 27)     45927       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 8, 8, 27)     0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 8, 8, 216)    0           concatenate_53[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 216)    864         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 216)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 27)     52488       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 8, 8, 27)     0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 8, 8, 243)    0           concatenate_54[0][0]             \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 243)    972         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 243)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 27)     6561        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 27)     0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 4, 4, 27)     0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 4, 4, 27)     108         average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 4, 4, 27)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 4, 4, 27)     6561        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 4, 4, 27)     0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 4, 4, 54)     0           average_pooling2d_6[0][0]        \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 4, 4, 54)     216         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 4, 4, 54)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 4, 4, 27)     13122       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 4, 4, 27)     0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 4, 4, 81)     0           concatenate_56[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 4, 4, 81)     324         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 4, 4, 81)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 4, 4, 27)     19683       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 4, 4, 27)     0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 4, 4, 108)    0           concatenate_57[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 4, 4, 108)    432         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 4, 4, 108)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 4, 4, 27)     26244       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 4, 4, 27)     0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 4, 4, 135)    0           concatenate_58[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 4, 4, 135)    540         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 4, 4, 135)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 4, 4, 27)     32805       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 4, 4, 27)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 4, 4, 162)    0           concatenate_59[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 4, 4, 162)    648         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 4, 4, 162)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 4, 4, 27)     39366       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 4, 4, 27)     0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 4, 4, 189)    0           concatenate_60[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 4, 4, 189)    756         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 4, 4, 189)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 4, 4, 27)     45927       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 4, 4, 27)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 4, 4, 216)    0           concatenate_61[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 4, 4, 216)    864         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 4, 4, 216)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 4, 4, 27)     52488       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 4, 4, 27)     0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 4, 4, 243)    0           concatenate_62[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 4, 4, 243)    972         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 4, 4, 243)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 2, 2, 243)    0           activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 972)          0           average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           9730        flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "*************************************after removing last dense layer******************************************\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 32, 32, 27)   324         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 32, 32, 27)   108         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 32, 32, 27)   0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 32, 32, 27)   6561        activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 32, 27)   0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 32, 32, 54)   0           conv2d_36[0][0]                  \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 32, 32, 54)   216         concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 32, 32, 54)   0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 32, 32, 27)   13122       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 27)   0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 32, 32, 81)   0           concatenate_32[0][0]             \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 32, 32, 81)   324         concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 32, 32, 81)   0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 32, 32, 27)   19683       activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 27)   0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 32, 32, 108)  0           concatenate_33[0][0]             \n",
      "                                                                 dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 32, 32, 108)  432         concatenate_34[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 32, 32, 108)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 32, 32, 27)   26244       activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 32, 32, 27)   0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 32, 32, 135)  0           concatenate_34[0][0]             \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 32, 32, 135)  540         concatenate_35[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 32, 32, 135)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 32, 32, 27)   32805       activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 27)   0           conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 32, 32, 162)  0           concatenate_35[0][0]             \n",
      "                                                                 dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 32, 32, 162)  648         concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 32, 32, 162)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 32, 32, 27)   39366       activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 27)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_37 (Concatenate)    (None, 32, 32, 189)  0           concatenate_36[0][0]             \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 32, 32, 189)  756         concatenate_37[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 32, 32, 189)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 32, 32, 27)   45927       activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 27)   0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_38 (Concatenate)    (None, 32, 32, 216)  0           concatenate_37[0][0]             \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 32, 32, 216)  864         concatenate_38[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 32, 32, 216)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 32, 32, 27)   52488       activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 27)   0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_39 (Concatenate)    (None, 32, 32, 243)  0           concatenate_38[0][0]             \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 32, 32, 243)  972         concatenate_39[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 32, 32, 243)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 27)   6561        activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 27)   0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 16, 16, 27)   0           dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 16, 16, 27)   108         average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16, 16, 27)   0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 16, 16, 27)   6561        activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 27)   0           conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_40 (Concatenate)    (None, 16, 16, 54)   0           average_pooling2d_4[0][0]        \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 16, 16, 54)   216         concatenate_40[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 16, 16, 54)   0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 16, 16, 27)   13122       activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 16, 27)   0           conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_41 (Concatenate)    (None, 16, 16, 81)   0           concatenate_40[0][0]             \n",
      "                                                                 dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 16, 16, 81)   324         concatenate_41[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 16, 16, 81)   0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 27)   19683       activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, 16, 27)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_42 (Concatenate)    (None, 16, 16, 108)  0           concatenate_41[0][0]             \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 16, 16, 108)  432         concatenate_42[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 16, 16, 108)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 16, 16, 27)   26244       activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 16, 16, 27)   0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_43 (Concatenate)    (None, 16, 16, 135)  0           concatenate_42[0][0]             \n",
      "                                                                 dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 16, 16, 135)  540         concatenate_43[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 16, 16, 135)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 27)   32805       activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 16, 16, 27)   0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_44 (Concatenate)    (None, 16, 16, 162)  0           concatenate_43[0][0]             \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 16, 16, 162)  648         concatenate_44[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 162)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 16, 16, 27)   39366       activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 16, 16, 27)   0           conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_45 (Concatenate)    (None, 16, 16, 189)  0           concatenate_44[0][0]             \n",
      "                                                                 dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 16, 16, 189)  756         concatenate_45[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16, 16, 189)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 16, 16, 27)   45927       activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 16, 16, 27)   0           conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_46 (Concatenate)    (None, 16, 16, 216)  0           concatenate_45[0][0]             \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 16, 16, 216)  864         concatenate_46[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 216)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 16, 16, 27)   52488       activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 16, 16, 27)   0           conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_47 (Concatenate)    (None, 16, 16, 243)  0           concatenate_46[0][0]             \n",
      "                                                                 dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 16, 16, 243)  972         concatenate_47[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 16, 16, 243)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 16, 16, 27)   6561        activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 16, 16, 27)   0           conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 8, 8, 27)     0           dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 8, 8, 27)     108         average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 8, 8, 27)     0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 8, 8, 27)     6561        activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 8, 8, 27)     0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_48 (Concatenate)    (None, 8, 8, 54)     0           average_pooling2d_5[0][0]        \n",
      "                                                                 dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 8, 8, 54)     216         concatenate_48[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 8, 8, 54)     0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 8, 8, 27)     13122       activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 8, 8, 27)     0           conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_49 (Concatenate)    (None, 8, 8, 81)     0           concatenate_48[0][0]             \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 8, 8, 81)     324         concatenate_49[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 8, 8, 81)     0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 8, 8, 27)     19683       activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 8, 8, 27)     0           conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_50 (Concatenate)    (None, 8, 8, 108)    0           concatenate_49[0][0]             \n",
      "                                                                 dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 8, 8, 108)    432         concatenate_50[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 8, 8, 108)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 8, 8, 27)     26244       activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 8, 8, 27)     0           conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_51 (Concatenate)    (None, 8, 8, 135)    0           concatenate_50[0][0]             \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 8, 8, 135)    540         concatenate_51[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 8, 8, 135)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 8, 8, 27)     32805       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 8, 8, 27)     0           conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_52 (Concatenate)    (None, 8, 8, 162)    0           concatenate_51[0][0]             \n",
      "                                                                 dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 8, 8, 162)    648         concatenate_52[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 8, 8, 162)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 8, 8, 27)     39366       activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 8, 8, 27)     0           conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_53 (Concatenate)    (None, 8, 8, 189)    0           concatenate_52[0][0]             \n",
      "                                                                 dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 8, 8, 189)    756         concatenate_53[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 8, 8, 189)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 8, 8, 27)     45927       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 8, 8, 27)     0           conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_54 (Concatenate)    (None, 8, 8, 216)    0           concatenate_53[0][0]             \n",
      "                                                                 dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 8, 8, 216)    864         concatenate_54[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 8, 8, 216)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 8, 8, 27)     52488       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 8, 8, 27)     0           conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_55 (Concatenate)    (None, 8, 8, 243)    0           concatenate_54[0][0]             \n",
      "                                                                 dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 8, 8, 243)    972         concatenate_55[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 8, 8, 243)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 8, 8, 27)     6561        activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 8, 8, 27)     0           conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 4, 4, 27)     0           dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 4, 4, 27)     108         average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 4, 4, 27)     0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 4, 4, 27)     6561        activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 4, 4, 27)     0           conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_56 (Concatenate)    (None, 4, 4, 54)     0           average_pooling2d_6[0][0]        \n",
      "                                                                 dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 4, 4, 54)     216         concatenate_56[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 4, 4, 54)     0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 4, 4, 27)     13122       activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 4, 4, 27)     0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_57 (Concatenate)    (None, 4, 4, 81)     0           concatenate_56[0][0]             \n",
      "                                                                 dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 4, 4, 81)     324         concatenate_57[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 4, 4, 81)     0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 4, 4, 27)     19683       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 4, 4, 27)     0           conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_58 (Concatenate)    (None, 4, 4, 108)    0           concatenate_57[0][0]             \n",
      "                                                                 dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 4, 4, 108)    432         concatenate_58[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 4, 4, 108)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 4, 4, 27)     26244       activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 4, 4, 27)     0           conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_59 (Concatenate)    (None, 4, 4, 135)    0           concatenate_58[0][0]             \n",
      "                                                                 dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 4, 4, 135)    540         concatenate_59[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 4, 4, 135)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 4, 4, 27)     32805       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 4, 4, 27)     0           conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_60 (Concatenate)    (None, 4, 4, 162)    0           concatenate_59[0][0]             \n",
      "                                                                 dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 4, 4, 162)    648         concatenate_60[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 4, 4, 162)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 4, 4, 27)     39366       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 4, 4, 27)     0           conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_61 (Concatenate)    (None, 4, 4, 189)    0           concatenate_60[0][0]             \n",
      "                                                                 dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 4, 4, 189)    756         concatenate_61[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 4, 4, 189)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 4, 4, 27)     45927       activation_69[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 4, 4, 27)     0           conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_62 (Concatenate)    (None, 4, 4, 216)    0           concatenate_61[0][0]             \n",
      "                                                                 dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 4, 4, 216)    864         concatenate_62[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 4, 4, 216)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 4, 4, 27)     52488       activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 4, 4, 27)     0           conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_63 (Concatenate)    (None, 4, 4, 243)    0           concatenate_62[0][0]             \n",
      "                                                                 dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 4, 4, 243)    972         concatenate_63[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 4, 4, 243)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 2, 2, 243)    0           activation_71[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 984,231\n",
      "Trainable params: 974,511\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "**************************************after adding conv2d layer****************************************\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_5 (Functional)    (None, 2, 2, 243)         984231    \n",
      "_________________________________________________________________\n",
      "conv2d_72 (Conv2D)           (None, 1, 1, 10)          9730      \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "_________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Epoch 1/10\n",
      "  2/391 [..............................] - ETA: 33s - loss: 2.5705 - accuracy: 0.1094WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0608s vs `on_train_batch_end` time: 0.1048s). Check your callbacks.\n",
      "391/391 [==============================] - 71s 183ms/step - loss: 2.0123 - accuracy: 0.2608 - val_loss: 2.1333 - val_accuracy: 0.2932\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 71s 181ms/step - loss: 1.7144 - accuracy: 0.3684 - val_loss: 1.8513 - val_accuracy: 0.3589\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 72s 184ms/step - loss: 1.5591 - accuracy: 0.4290 - val_loss: 1.7719 - val_accuracy: 0.3882\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 1.4613 - accuracy: 0.4681 - val_loss: 1.8698 - val_accuracy: 0.4131\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 1.3781 - accuracy: 0.5009 - val_loss: 1.4719 - val_accuracy: 0.4841\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 1.3133 - accuracy: 0.5245 - val_loss: 1.6696 - val_accuracy: 0.4614\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 1.2600 - accuracy: 0.5482 - val_loss: 1.8897 - val_accuracy: 0.4513\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 1.2208 - accuracy: 0.5621 - val_loss: 1.5176 - val_accuracy: 0.5132\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 1.1779 - accuracy: 0.5808 - val_loss: 1.9051 - val_accuracy: 0.4623\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 1.1440 - accuracy: 0.5896 - val_loss: 1.4295 - val_accuracy: 0.5387\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 1.5103 - accuracy: 0.5190\n",
      "Test loss: 1.5103108882904053\n",
      "Test accuracy: 0.5189999938011169\n"
     ]
    }
   ],
   "source": [
    "v_h_shift_model=modell(X_train_hor_ver_shift,X_cv_hor_ver_shift,X_test_hor_ver_shift,y_train,y_cv,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image augumentation horizontal and vertical flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "49pJUbN0uIYE"
   },
   "outputs": [],
   "source": [
    "# Reff https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "\n",
    "def vertical_horizontal_flip(arr_imgs):\n",
    "\n",
    "      # convert to numpy array\n",
    "      d_ar = arr_imgs.copy()\n",
    "      \n",
    "      for i in tqdm(range(d_ar.shape[0]), position=0):\n",
    "          data = d_ar[i]\n",
    "          # expand dimension to one sample\n",
    "          samples = np.expand_dims(data, 0)\n",
    "          # create image data augmentation generator\n",
    "          datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True)\n",
    "          # prepare iterator\n",
    "          it = datagen.flow(samples, batch_size=1)\n",
    "          # generate samples and plot\n",
    "          # define subplot\n",
    "          # pyplot.subplot(330 + 1 + i)\n",
    "          # generate batch of images\n",
    "          #for j in range(9):\n",
    "          batch = it.next()     \n",
    "              #if j == 0:\n",
    "\n",
    "                  # convert to unsigned integers for viewing\n",
    "          image = batch[0].astype('uint8')\n",
    "          d_ar[i] = image\n",
    "                  # plot raw pixel data\n",
    "                  #break\n",
    "      return d_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "QSV0myRvzb0P",
    "outputId": "81c2ba62-2487-4985-d884-927378c0bd23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:11<00:00, 4254.57it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4128.43it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4373.36it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_hor_ver_flip=vertical_horizontal_flip(X_train)\n",
    "X_cv_hor_ver_flip=vertical_horizontal_flip(X_cv)\n",
    "X_test_hor_ver_flip=vertical_horizontal_flip(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jw1RiDTjz16F",
    "outputId": "8831eb5f-57bc-4fa4-837a-e6864c066020",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 32, 32, 27)   324         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 32, 32, 27)   108         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 32, 32, 27)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 32, 32, 27)   6561        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 32, 32, 27)   0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 32, 32, 54)   0           conv2d_73[0][0]                  \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 32, 32, 54)   216         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 32, 32, 54)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 32, 32, 27)   13122       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 32, 32, 27)   0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 32, 32, 81)   0           concatenate_64[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 32, 32, 81)   324         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 32, 32, 81)   0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 27)   19683       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 32, 32, 27)   0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 32, 32, 108)  0           concatenate_65[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 32, 32, 108)  432         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 32, 32, 108)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 27)   26244       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 32, 32, 27)   0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 32, 32, 135)  0           concatenate_66[0][0]             \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 32, 32, 135)  540         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 32, 32, 135)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 27)   32805       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 32, 32, 27)   0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 32, 32, 162)  0           concatenate_67[0][0]             \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 32, 32, 162)  648         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 32, 32, 162)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 27)   39366       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 32, 32, 27)   0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 32, 32, 189)  0           concatenate_68[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 32, 32, 189)  756         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 32, 32, 189)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 27)   45927       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 32, 32, 27)   0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 32, 32, 216)  0           concatenate_69[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 32, 32, 216)  864         concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 32, 32, 216)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 27)   52488       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 32, 32, 27)   0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 32, 32, 243)  0           concatenate_70[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 32, 32, 243)  972         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 32, 32, 243)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 27)   6561        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 32, 32, 27)   0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 16, 16, 27)   0           dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 16, 16, 27)   108         average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 16, 16, 27)   0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 27)   6561        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 16, 16, 27)   0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 16, 16, 54)   0           average_pooling2d_8[0][0]        \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 16, 16, 54)   216         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 16, 16, 54)   0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 16, 16, 27)   13122       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 16, 16, 27)   0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 16, 16, 81)   0           concatenate_72[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 16, 16, 81)   324         concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 16, 16, 81)   0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 27)   19683       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 16, 16, 27)   0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 16, 16, 108)  0           concatenate_73[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 16, 16, 108)  432         concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 16, 16, 108)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 27)   26244       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16, 16, 27)   0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 16, 16, 135)  0           concatenate_74[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 16, 16, 135)  540         concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 16, 16, 135)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 27)   32805       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 16, 16, 27)   0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 16, 16, 162)  0           concatenate_75[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 16, 16, 162)  648         concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 16, 16, 162)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 27)   39366       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 16, 16, 27)   0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 16, 16, 189)  0           concatenate_76[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 16, 16, 189)  756         concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 16, 16, 189)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 27)   45927       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 16, 16, 27)   0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 16, 16, 216)  0           concatenate_77[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 16, 16, 216)  864         concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 16, 16, 216)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 27)   52488       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 16, 16, 27)   0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 16, 16, 243)  0           concatenate_78[0][0]             \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 16, 16, 243)  972         concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 16, 16, 243)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 16, 16, 27)   6561        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 16, 16, 27)   0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 27)     0           dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 27)     108         average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 27)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 27)     6561        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 8, 8, 27)     0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 8, 8, 54)     0           average_pooling2d_9[0][0]        \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 54)     216         concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 54)     0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 27)     13122       activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 8, 8, 27)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 8, 8, 81)     0           concatenate_80[0][0]             \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 81)     324         concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 81)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 27)     19683       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 8, 8, 27)     0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 8, 8, 108)    0           concatenate_81[0][0]             \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 108)    432         concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 108)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 27)     26244       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 8, 8, 27)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 8, 8, 135)    0           concatenate_82[0][0]             \n",
      "                                                                 dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 135)    540         concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 135)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 27)     32805       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 8, 8, 27)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 8, 8, 162)    0           concatenate_83[0][0]             \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 162)    648         concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 162)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 27)     39366       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 8, 8, 27)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 8, 8, 189)    0           concatenate_84[0][0]             \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 189)    756         concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 189)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 27)     45927       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 8, 8, 27)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 8, 8, 216)    0           concatenate_85[0][0]             \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 216)    864         concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 216)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 27)     52488       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 8, 8, 27)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 8, 8, 243)    0           concatenate_86[0][0]             \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 243)    972         concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 243)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 27)     6561        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 8, 8, 27)     0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 4, 4, 27)     0           dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 4, 4, 27)     108         average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 4, 4, 27)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 4, 4, 27)     6561        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 4, 4, 27)     0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 4, 4, 54)     0           average_pooling2d_10[0][0]       \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 4, 4, 54)     216         concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 4, 4, 54)     0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 4, 27)     13122       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 4, 4, 27)     0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 4, 4, 81)     0           concatenate_88[0][0]             \n",
      "                                                                 dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 4, 4, 81)     324         concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 4, 4, 81)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 27)     19683       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 4, 4, 27)     0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 4, 4, 108)    0           concatenate_89[0][0]             \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 4, 4, 108)    432         concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 4, 4, 108)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 4, 27)     26244       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 4, 4, 27)     0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 4, 4, 135)    0           concatenate_90[0][0]             \n",
      "                                                                 dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 4, 4, 135)    540         concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 4, 4, 135)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 4, 4, 27)     32805       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 4, 4, 27)     0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 4, 4, 162)    0           concatenate_91[0][0]             \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 4, 4, 162)    648         concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 4, 4, 162)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 4, 4, 27)     39366       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 4, 4, 27)     0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 4, 4, 189)    0           concatenate_92[0][0]             \n",
      "                                                                 dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 4, 4, 189)    756         concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 4, 4, 189)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 4, 4, 27)     45927       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 4, 4, 27)     0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 4, 4, 216)    0           concatenate_93[0][0]             \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 4, 4, 216)    864         concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 4, 4, 216)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 27)     52488       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 4, 4, 27)     0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 4, 4, 243)    0           concatenate_94[0][0]             \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 4, 4, 243)    972         concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 4, 4, 243)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 2, 2, 243)    0           activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 972)          0           average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           9730        flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "*************************************after removing last dense layer******************************************\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Model: \"functional_9\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 32, 32, 27)   324         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 32, 32, 27)   108         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 32, 32, 27)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 32, 32, 27)   6561        activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 32, 32, 27)   0           conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_64 (Concatenate)    (None, 32, 32, 54)   0           conv2d_73[0][0]                  \n",
      "                                                                 dropout_35[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 32, 32, 54)   216         concatenate_64[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 32, 32, 54)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 32, 32, 27)   13122       activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_36 (Dropout)            (None, 32, 32, 27)   0           conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_65 (Concatenate)    (None, 32, 32, 81)   0           concatenate_64[0][0]             \n",
      "                                                                 dropout_36[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 32, 32, 81)   324         concatenate_65[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 32, 32, 81)   0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 32, 32, 27)   19683       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 32, 32, 27)   0           conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_66 (Concatenate)    (None, 32, 32, 108)  0           concatenate_65[0][0]             \n",
      "                                                                 dropout_37[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 32, 32, 108)  432         concatenate_66[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 32, 32, 108)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 32, 32, 27)   26244       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)            (None, 32, 32, 27)   0           conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_67 (Concatenate)    (None, 32, 32, 135)  0           concatenate_66[0][0]             \n",
      "                                                                 dropout_38[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 32, 32, 135)  540         concatenate_67[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 32, 32, 135)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 32, 32, 27)   32805       activation_76[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_39 (Dropout)            (None, 32, 32, 27)   0           conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_68 (Concatenate)    (None, 32, 32, 162)  0           concatenate_67[0][0]             \n",
      "                                                                 dropout_39[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 32, 32, 162)  648         concatenate_68[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 32, 32, 162)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 32, 32, 27)   39366       activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_40 (Dropout)            (None, 32, 32, 27)   0           conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_69 (Concatenate)    (None, 32, 32, 189)  0           concatenate_68[0][0]             \n",
      "                                                                 dropout_40[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 32, 32, 189)  756         concatenate_69[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 32, 32, 189)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 32, 32, 27)   45927       activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_41 (Dropout)            (None, 32, 32, 27)   0           conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_70 (Concatenate)    (None, 32, 32, 216)  0           concatenate_69[0][0]             \n",
      "                                                                 dropout_41[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 32, 32, 216)  864         concatenate_70[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 32, 32, 216)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 32, 32, 27)   52488       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_42 (Dropout)            (None, 32, 32, 27)   0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_71 (Concatenate)    (None, 32, 32, 243)  0           concatenate_70[0][0]             \n",
      "                                                                 dropout_42[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 32, 32, 243)  972         concatenate_71[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 32, 32, 243)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 32, 32, 27)   6561        activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_43 (Dropout)            (None, 32, 32, 27)   0           conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 16, 16, 27)   0           dropout_43[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 16, 16, 27)   108         average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 16, 16, 27)   0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 16, 16, 27)   6561        activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_44 (Dropout)            (None, 16, 16, 27)   0           conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_72 (Concatenate)    (None, 16, 16, 54)   0           average_pooling2d_8[0][0]        \n",
      "                                                                 dropout_44[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 16, 16, 54)   216         concatenate_72[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 16, 16, 54)   0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 16, 16, 27)   13122       activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_45 (Dropout)            (None, 16, 16, 27)   0           conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_73 (Concatenate)    (None, 16, 16, 81)   0           concatenate_72[0][0]             \n",
      "                                                                 dropout_45[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 16, 16, 81)   324         concatenate_73[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 16, 16, 81)   0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 16, 16, 27)   19683       activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_46 (Dropout)            (None, 16, 16, 27)   0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_74 (Concatenate)    (None, 16, 16, 108)  0           concatenate_73[0][0]             \n",
      "                                                                 dropout_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 16, 16, 108)  432         concatenate_74[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 16, 16, 108)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 16, 16, 27)   26244       activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_47 (Dropout)            (None, 16, 16, 27)   0           conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_75 (Concatenate)    (None, 16, 16, 135)  0           concatenate_74[0][0]             \n",
      "                                                                 dropout_47[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 16, 16, 135)  540         concatenate_75[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 16, 16, 135)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 16, 16, 27)   32805       activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_48 (Dropout)            (None, 16, 16, 27)   0           conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_76 (Concatenate)    (None, 16, 16, 162)  0           concatenate_75[0][0]             \n",
      "                                                                 dropout_48[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 16, 16, 162)  648         concatenate_76[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 16, 16, 162)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 16, 16, 27)   39366       activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 16, 16, 27)   0           conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_77 (Concatenate)    (None, 16, 16, 189)  0           concatenate_76[0][0]             \n",
      "                                                                 dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 16, 16, 189)  756         concatenate_77[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 16, 16, 189)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 16, 16, 27)   45927       activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 16, 16, 27)   0           conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_78 (Concatenate)    (None, 16, 16, 216)  0           concatenate_77[0][0]             \n",
      "                                                                 dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 16, 16, 216)  864         concatenate_78[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 16, 16, 216)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 16, 16, 27)   52488       activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 16, 16, 27)   0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_79 (Concatenate)    (None, 16, 16, 243)  0           concatenate_78[0][0]             \n",
      "                                                                 dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 16, 16, 243)  972         concatenate_79[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 16, 16, 243)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 16, 16, 27)   6561        activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 16, 16, 27)   0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 8, 8, 27)     0           dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 8, 8, 27)     108         average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 8, 8, 27)     0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 8, 8, 27)     6561        activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 8, 8, 27)     0           conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_80 (Concatenate)    (None, 8, 8, 54)     0           average_pooling2d_9[0][0]        \n",
      "                                                                 dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 8, 8, 54)     216         concatenate_80[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 8, 8, 54)     0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 8, 8, 27)     13122       activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 8, 8, 27)     0           conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_81 (Concatenate)    (None, 8, 8, 81)     0           concatenate_80[0][0]             \n",
      "                                                                 dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 8, 8, 81)     324         concatenate_81[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 8, 8, 81)     0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 8, 8, 27)     19683       activation_92[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 8, 8, 27)     0           conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_82 (Concatenate)    (None, 8, 8, 108)    0           concatenate_81[0][0]             \n",
      "                                                                 dropout_55[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 8, 8, 108)    432         concatenate_82[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 8, 8, 108)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 8, 8, 27)     26244       activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_56 (Dropout)            (None, 8, 8, 27)     0           conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_83 (Concatenate)    (None, 8, 8, 135)    0           concatenate_82[0][0]             \n",
      "                                                                 dropout_56[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 8, 8, 135)    540         concatenate_83[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 8, 8, 135)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 8, 8, 27)     32805       activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_57 (Dropout)            (None, 8, 8, 27)     0           conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_84 (Concatenate)    (None, 8, 8, 162)    0           concatenate_83[0][0]             \n",
      "                                                                 dropout_57[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 8, 8, 162)    648         concatenate_84[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 8, 8, 162)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 8, 8, 27)     39366       activation_95[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_58 (Dropout)            (None, 8, 8, 27)     0           conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_85 (Concatenate)    (None, 8, 8, 189)    0           concatenate_84[0][0]             \n",
      "                                                                 dropout_58[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 8, 8, 189)    756         concatenate_85[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 8, 8, 189)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 8, 8, 27)     45927       activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_59 (Dropout)            (None, 8, 8, 27)     0           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_86 (Concatenate)    (None, 8, 8, 216)    0           concatenate_85[0][0]             \n",
      "                                                                 dropout_59[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 8, 8, 216)    864         concatenate_86[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 8, 8, 216)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 8, 8, 27)     52488       activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_60 (Dropout)            (None, 8, 8, 27)     0           conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_87 (Concatenate)    (None, 8, 8, 243)    0           concatenate_86[0][0]             \n",
      "                                                                 dropout_60[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 8, 8, 243)    972         concatenate_87[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 8, 8, 243)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 8, 8, 27)     6561        activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_61 (Dropout)            (None, 8, 8, 27)     0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 4, 4, 27)     0           dropout_61[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 4, 4, 27)     108         average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 4, 4, 27)     0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 4, 4, 27)     6561        activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 4, 4, 27)     0           conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_88 (Concatenate)    (None, 4, 4, 54)     0           average_pooling2d_10[0][0]       \n",
      "                                                                 dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 4, 4, 54)     216         concatenate_88[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 4, 4, 54)     0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 4, 4, 27)     13122       activation_100[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 4, 4, 27)     0           conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_89 (Concatenate)    (None, 4, 4, 81)     0           concatenate_88[0][0]             \n",
      "                                                                 dropout_63[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 4, 4, 81)     324         concatenate_89[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 4, 4, 81)     0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 4, 4, 27)     19683       activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_64 (Dropout)            (None, 4, 4, 27)     0           conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_90 (Concatenate)    (None, 4, 4, 108)    0           concatenate_89[0][0]             \n",
      "                                                                 dropout_64[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 4, 4, 108)    432         concatenate_90[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 4, 4, 108)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 4, 4, 27)     26244       activation_102[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_65 (Dropout)            (None, 4, 4, 27)     0           conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_91 (Concatenate)    (None, 4, 4, 135)    0           concatenate_90[0][0]             \n",
      "                                                                 dropout_65[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 4, 4, 135)    540         concatenate_91[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 4, 4, 135)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 4, 4, 27)     32805       activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_66 (Dropout)            (None, 4, 4, 27)     0           conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_92 (Concatenate)    (None, 4, 4, 162)    0           concatenate_91[0][0]             \n",
      "                                                                 dropout_66[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 4, 4, 162)    648         concatenate_92[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 4, 4, 162)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 4, 4, 27)     39366       activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_67 (Dropout)            (None, 4, 4, 27)     0           conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_93 (Concatenate)    (None, 4, 4, 189)    0           concatenate_92[0][0]             \n",
      "                                                                 dropout_67[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 4, 4, 189)    756         concatenate_93[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 4, 4, 189)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 4, 4, 27)     45927       activation_105[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_68 (Dropout)            (None, 4, 4, 27)     0           conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_94 (Concatenate)    (None, 4, 4, 216)    0           concatenate_93[0][0]             \n",
      "                                                                 dropout_68[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 4, 4, 216)    864         concatenate_94[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 4, 4, 216)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 4, 4, 27)     52488       activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_69 (Dropout)            (None, 4, 4, 27)     0           conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_95 (Concatenate)    (None, 4, 4, 243)    0           concatenate_94[0][0]             \n",
      "                                                                 dropout_69[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 4, 4, 243)    972         concatenate_95[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 4, 4, 243)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 2, 2, 243)    0           activation_107[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 984,231\n",
      "Trainable params: 974,511\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "**************************************after adding conv2d layer****************************************\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_9 (Functional)    (None, 2, 2, 243)         984231    \n",
      "_________________________________________________________________\n",
      "conv2d_109 (Conv2D)          (None, 1, 1, 10)          9730      \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "_________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Epoch 1/10\n",
      "  2/391 [..............................] - ETA: 1:03 - loss: 2.4208 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0617s vs `on_train_batch_end` time: 0.1070s). Check your callbacks.\n",
      "391/391 [==============================] - 70s 179ms/step - loss: 1.5745 - accuracy: 0.4186 - val_loss: 2.4245 - val_accuracy: 0.3178\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 71s 181ms/step - loss: 1.1657 - accuracy: 0.5767 - val_loss: 1.4428 - val_accuracy: 0.5289\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 72s 184ms/step - loss: 0.9974 - accuracy: 0.6384 - val_loss: 1.6193 - val_accuracy: 0.4919\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 0.8951 - accuracy: 0.6760 - val_loss: 1.0396 - val_accuracy: 0.6429\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.8182 - accuracy: 0.7049 - val_loss: 1.0979 - val_accuracy: 0.6538\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.7572 - accuracy: 0.7287 - val_loss: 0.8281 - val_accuracy: 0.7200\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.7100 - accuracy: 0.7447 - val_loss: 0.8919 - val_accuracy: 0.7016\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.6686 - accuracy: 0.7593 - val_loss: 1.1034 - val_accuracy: 0.6838\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.6262 - accuracy: 0.7763 - val_loss: 1.9446 - val_accuracy: 0.5212\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.5946 - accuracy: 0.7879 - val_loss: 0.7956 - val_accuracy: 0.7368\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.8907 - accuracy: 0.7170\n",
      "Test loss: 0.8907139897346497\n",
      "Test accuracy: 0.7170000076293945\n"
     ]
    }
   ],
   "source": [
    "v_h_flip_model=modell(X_train_hor_ver_flip,X_cv_hor_ver_flip,X_test_hor_ver_flip,y_train,y_cv,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image augumentation brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N3W-CwPi38Aj"
   },
   "outputs": [],
   "source": [
    "# Reff https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "\n",
    "def brightness(arr_imgs):\n",
    "\n",
    "      # convert to numpy array\n",
    "      d_ar = arr_imgs.copy()\n",
    "      \n",
    "      for i in tqdm(range(d_ar.shape[0]), position=0):\n",
    "          data = d_ar[i]\n",
    "          # expand dimension to one sample\n",
    "          samples = np.expand_dims(data, 0)\n",
    "          # create image data augmentation generator\n",
    "          datagen = ImageDataGenerator(brightness_range=[0.2,1.0])\n",
    "          # prepare iterator\n",
    "          it = datagen.flow(samples, batch_size=1)\n",
    "          # generate samples and plot\n",
    "          # define subplot\n",
    "          # pyplot.subplot(330 + 1 + i)\n",
    "          # generate batch of images\n",
    "          #for j in range(9):\n",
    "          batch = it.next()     \n",
    "              #if j == 0:\n",
    "\n",
    "                  # convert to unsigned integers for viewing\n",
    "          image = batch[0].astype('uint8')\n",
    "          d_ar[i] = image\n",
    "                  # plot raw pixel data\n",
    "                  #break\n",
    "      return d_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "f0-tnVuX0ONq",
    "outputId": "9dec8a8e-4c2f-48b9-ab74-9e0cf2c1323c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:19<00:00, 2546.58it/s]\n",
      "100%|██████████| 10000/10000 [00:03<00:00, 2511.73it/s]\n",
      "100%|██████████| 10000/10000 [00:04<00:00, 2483.87it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_bright=brightness(X_train)\n",
    "X_cv_bright=brightness(X_cv)\n",
    "X_test_bright=brightness(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rkoZ8Jmv4YO0",
    "outputId": "a0fcbfe4-50e8-4468-b0b4-009aefbfa03b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_11\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 32, 32, 27)   324         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 32, 32, 27)   108         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 32, 32, 27)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 32, 32, 27)   6561        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 32, 32, 27)   0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 32, 32, 54)   0           conv2d_110[0][0]                 \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 32, 32, 54)   216         concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 32, 32, 54)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 32, 32, 27)   13122       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 32, 32, 27)   0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 32, 32, 81)   0           concatenate_96[0][0]             \n",
      "                                                                 dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 32, 32, 81)   324         concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 32, 32, 81)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 32, 32, 27)   19683       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 32, 32, 27)   0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 32, 32, 108)  0           concatenate_97[0][0]             \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 32, 32, 108)  432         concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 32, 32, 108)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 32, 32, 27)   26244       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 32, 32, 27)   0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 32, 32, 135)  0           concatenate_98[0][0]             \n",
      "                                                                 dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 32, 32, 135)  540         concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 32, 32, 135)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 32, 32, 27)   32805       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 32, 32, 27)   0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 32, 32, 162)  0           concatenate_99[0][0]             \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 32, 32, 162)  648         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 32, 32, 162)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 32, 32, 27)   39366       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 32, 32, 27)   0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 32, 32, 189)  0           concatenate_100[0][0]            \n",
      "                                                                 dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 32, 32, 189)  756         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 32, 32, 189)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 32, 32, 27)   45927       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 32, 32, 27)   0           conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 32, 32, 216)  0           concatenate_101[0][0]            \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 32, 32, 216)  864         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 32, 32, 216)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 32, 32, 27)   52488       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 32, 32, 27)   0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 32, 32, 243)  0           concatenate_102[0][0]            \n",
      "                                                                 dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 32, 32, 243)  972         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 32, 32, 243)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 32, 32, 27)   6561        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 32, 32, 27)   0           conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 16, 16, 27)   0           dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 27)   108         average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 27)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 16, 16, 27)   6561        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 16, 16, 27)   0           conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 16, 16, 54)   0           average_pooling2d_12[0][0]       \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 54)   216         concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 54)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 27)   13122       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 16, 16, 27)   0           conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 16, 16, 81)   0           concatenate_104[0][0]            \n",
      "                                                                 dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 81)   324         concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 81)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 27)   19683       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 16, 16, 27)   0           conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 16, 16, 108)  0           concatenate_105[0][0]            \n",
      "                                                                 dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 16, 16, 108)  432         concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 16, 16, 108)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 16, 16, 27)   26244       activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 16, 16, 27)   0           conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 16, 16, 135)  0           concatenate_106[0][0]            \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 16, 16, 135)  540         concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 135)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 16, 16, 27)   32805       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 16, 16, 27)   0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 16, 16, 162)  0           concatenate_107[0][0]            \n",
      "                                                                 dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 162)  648         concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 162)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 16, 16, 27)   39366       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 16, 16, 27)   0           conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 16, 16, 189)  0           concatenate_108[0][0]            \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 16, 16, 189)  756         concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 16, 16, 189)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 16, 16, 27)   45927       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 16, 16, 27)   0           conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 16, 16, 216)  0           concatenate_109[0][0]            \n",
      "                                                                 dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 16, 16, 216)  864         concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 16, 16, 216)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 16, 16, 27)   52488       activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 16, 16, 27)   0           conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 16, 16, 243)  0           concatenate_110[0][0]            \n",
      "                                                                 dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 16, 16, 243)  972         concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 16, 16, 243)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 16, 16, 27)   6561        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 16, 16, 27)   0           conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 8, 8, 27)     0           dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 8, 8, 27)     108         average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 8, 8, 27)     0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 8, 27)     6561        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 8, 8, 27)     0           conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 8, 8, 54)     0           average_pooling2d_13[0][0]       \n",
      "                                                                 dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 8, 8, 54)     216         concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 8, 8, 54)     0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 8, 8, 27)     13122       activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 8, 8, 27)     0           conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 8, 8, 81)     0           concatenate_112[0][0]            \n",
      "                                                                 dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 8, 8, 81)     324         concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 8, 8, 81)     0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 8, 8, 27)     19683       activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 8, 8, 27)     0           conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 8, 8, 108)    0           concatenate_113[0][0]            \n",
      "                                                                 dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 8, 8, 108)    432         concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 8, 8, 108)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 8, 8, 27)     26244       activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 8, 8, 27)     0           conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 8, 8, 135)    0           concatenate_114[0][0]            \n",
      "                                                                 dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 8, 8, 135)    540         concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 8, 8, 135)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 8, 8, 27)     32805       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 8, 8, 27)     0           conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 8, 8, 162)    0           concatenate_115[0][0]            \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 8, 8, 162)    648         concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 8, 8, 162)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 8, 8, 27)     39366       activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 8, 8, 27)     0           conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 8, 8, 189)    0           concatenate_116[0][0]            \n",
      "                                                                 dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 8, 8, 189)    756         concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 8, 8, 189)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 8, 8, 27)     45927       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 8, 8, 27)     0           conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 8, 8, 216)    0           concatenate_117[0][0]            \n",
      "                                                                 dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 8, 8, 216)    864         concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 8, 8, 216)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 8, 8, 27)     52488       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 8, 8, 27)     0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 8, 8, 243)    0           concatenate_118[0][0]            \n",
      "                                                                 dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 8, 8, 243)    972         concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 8, 8, 243)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 8, 8, 27)     6561        activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 8, 8, 27)     0           conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 4, 4, 27)     0           dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 4, 4, 27)     108         average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 4, 4, 27)     0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 4, 4, 27)     6561        activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 4, 4, 27)     0           conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 4, 4, 54)     0           average_pooling2d_14[0][0]       \n",
      "                                                                 dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 4, 4, 54)     216         concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 4, 4, 54)     0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 4, 4, 27)     13122       activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 4, 4, 27)     0           conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 4, 4, 81)     0           concatenate_120[0][0]            \n",
      "                                                                 dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 4, 4, 81)     324         concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 4, 4, 81)     0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 4, 4, 27)     19683       activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 4, 4, 27)     0           conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 4, 4, 108)    0           concatenate_121[0][0]            \n",
      "                                                                 dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 4, 4, 108)    432         concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 4, 4, 108)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 4, 4, 27)     26244       activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 4, 4, 27)     0           conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 4, 4, 135)    0           concatenate_122[0][0]            \n",
      "                                                                 dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 4, 4, 135)    540         concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 4, 4, 135)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 4, 4, 27)     32805       activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 4, 4, 27)     0           conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 4, 4, 162)    0           concatenate_123[0][0]            \n",
      "                                                                 dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 4, 4, 162)    648         concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 4, 4, 162)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 4, 4, 27)     39366       activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 4, 4, 27)     0           conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 4, 4, 189)    0           concatenate_124[0][0]            \n",
      "                                                                 dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 4, 4, 189)    756         concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 4, 4, 189)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 4, 4, 27)     45927       activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 4, 4, 27)     0           conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 4, 4, 216)    0           concatenate_125[0][0]            \n",
      "                                                                 dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 4, 4, 216)    864         concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 4, 4, 216)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 4, 4, 27)     52488       activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 4, 4, 27)     0           conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 4, 4, 243)    0           concatenate_126[0][0]            \n",
      "                                                                 dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 4, 4, 243)    972         concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 4, 4, 243)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 2, 2, 243)    0           activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 972)          0           average_pooling2d_15[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 10)           9730        flatten_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "*************************************after removing last dense layer******************************************\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Model: \"functional_13\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 32, 32, 27)   324         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 32, 32, 27)   108         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 32, 32, 27)   0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 32, 32, 27)   6561        activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_70 (Dropout)            (None, 32, 32, 27)   0           conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_96 (Concatenate)    (None, 32, 32, 54)   0           conv2d_110[0][0]                 \n",
      "                                                                 dropout_70[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 32, 32, 54)   216         concatenate_96[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 32, 32, 54)   0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 32, 32, 27)   13122       activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_71 (Dropout)            (None, 32, 32, 27)   0           conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_97 (Concatenate)    (None, 32, 32, 81)   0           concatenate_96[0][0]             \n",
      "                                                                 dropout_71[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 32, 32, 81)   324         concatenate_97[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 32, 32, 81)   0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 32, 32, 27)   19683       activation_110[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_72 (Dropout)            (None, 32, 32, 27)   0           conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_98 (Concatenate)    (None, 32, 32, 108)  0           concatenate_97[0][0]             \n",
      "                                                                 dropout_72[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 32, 32, 108)  432         concatenate_98[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 32, 32, 108)  0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 32, 32, 27)   26244       activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_73 (Dropout)            (None, 32, 32, 27)   0           conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_99 (Concatenate)    (None, 32, 32, 135)  0           concatenate_98[0][0]             \n",
      "                                                                 dropout_73[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 32, 32, 135)  540         concatenate_99[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 32, 32, 135)  0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 32, 32, 27)   32805       activation_112[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_74 (Dropout)            (None, 32, 32, 27)   0           conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 32, 32, 162)  0           concatenate_99[0][0]             \n",
      "                                                                 dropout_74[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 32, 32, 162)  648         concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 32, 32, 162)  0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 32, 32, 27)   39366       activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_75 (Dropout)            (None, 32, 32, 27)   0           conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 32, 32, 189)  0           concatenate_100[0][0]            \n",
      "                                                                 dropout_75[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 32, 32, 189)  756         concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 32, 32, 189)  0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 32, 32, 27)   45927       activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_76 (Dropout)            (None, 32, 32, 27)   0           conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 32, 32, 216)  0           concatenate_101[0][0]            \n",
      "                                                                 dropout_76[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 32, 32, 216)  864         concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 32, 32, 216)  0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 32, 32, 27)   52488       activation_115[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_77 (Dropout)            (None, 32, 32, 27)   0           conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 32, 32, 243)  0           concatenate_102[0][0]            \n",
      "                                                                 dropout_77[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 32, 32, 243)  972         concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 32, 32, 243)  0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 32, 32, 27)   6561        activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_78 (Dropout)            (None, 32, 32, 27)   0           conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 16, 16, 27)   0           dropout_78[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 16, 16, 27)   108         average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 16, 16, 27)   0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 16, 16, 27)   6561        activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_79 (Dropout)            (None, 16, 16, 27)   0           conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 16, 16, 54)   0           average_pooling2d_12[0][0]       \n",
      "                                                                 dropout_79[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 16, 16, 54)   216         concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 16, 16, 54)   0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 16, 16, 27)   13122       activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_80 (Dropout)            (None, 16, 16, 27)   0           conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 16, 16, 81)   0           concatenate_104[0][0]            \n",
      "                                                                 dropout_80[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 16, 16, 81)   324         concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 16, 16, 81)   0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 16, 16, 27)   19683       activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_81 (Dropout)            (None, 16, 16, 27)   0           conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 16, 16, 108)  0           concatenate_105[0][0]            \n",
      "                                                                 dropout_81[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 16, 16, 108)  432         concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 16, 16, 108)  0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 16, 16, 27)   26244       activation_120[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_82 (Dropout)            (None, 16, 16, 27)   0           conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 16, 16, 135)  0           concatenate_106[0][0]            \n",
      "                                                                 dropout_82[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 16, 16, 135)  540         concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 16, 16, 135)  0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 16, 16, 27)   32805       activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_83 (Dropout)            (None, 16, 16, 27)   0           conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 16, 16, 162)  0           concatenate_107[0][0]            \n",
      "                                                                 dropout_83[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 16, 16, 162)  648         concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 16, 16, 162)  0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 16, 16, 27)   39366       activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_84 (Dropout)            (None, 16, 16, 27)   0           conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_109 (Concatenate)   (None, 16, 16, 189)  0           concatenate_108[0][0]            \n",
      "                                                                 dropout_84[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 16, 16, 189)  756         concatenate_109[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 16, 16, 189)  0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 16, 16, 27)   45927       activation_123[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_85 (Dropout)            (None, 16, 16, 27)   0           conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_110 (Concatenate)   (None, 16, 16, 216)  0           concatenate_109[0][0]            \n",
      "                                                                 dropout_85[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 16, 16, 216)  864         concatenate_110[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 16, 16, 216)  0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 16, 16, 27)   52488       activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_86 (Dropout)            (None, 16, 16, 27)   0           conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_111 (Concatenate)   (None, 16, 16, 243)  0           concatenate_110[0][0]            \n",
      "                                                                 dropout_86[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 16, 16, 243)  972         concatenate_111[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 16, 16, 243)  0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 16, 16, 27)   6561        activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_87 (Dropout)            (None, 16, 16, 27)   0           conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 8, 8, 27)     0           dropout_87[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 8, 8, 27)     108         average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 8, 8, 27)     0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 8, 8, 27)     6561        activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_88 (Dropout)            (None, 8, 8, 27)     0           conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_112 (Concatenate)   (None, 8, 8, 54)     0           average_pooling2d_13[0][0]       \n",
      "                                                                 dropout_88[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 8, 8, 54)     216         concatenate_112[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 8, 8, 54)     0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 8, 8, 27)     13122       activation_127[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_89 (Dropout)            (None, 8, 8, 27)     0           conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_113 (Concatenate)   (None, 8, 8, 81)     0           concatenate_112[0][0]            \n",
      "                                                                 dropout_89[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 8, 8, 81)     324         concatenate_113[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 8, 8, 81)     0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 8, 8, 27)     19683       activation_128[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_90 (Dropout)            (None, 8, 8, 27)     0           conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_114 (Concatenate)   (None, 8, 8, 108)    0           concatenate_113[0][0]            \n",
      "                                                                 dropout_90[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 8, 8, 108)    432         concatenate_114[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 8, 8, 108)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 8, 8, 27)     26244       activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_91 (Dropout)            (None, 8, 8, 27)     0           conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_115 (Concatenate)   (None, 8, 8, 135)    0           concatenate_114[0][0]            \n",
      "                                                                 dropout_91[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 8, 8, 135)    540         concatenate_115[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 8, 8, 135)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 8, 8, 27)     32805       activation_130[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_92 (Dropout)            (None, 8, 8, 27)     0           conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_116 (Concatenate)   (None, 8, 8, 162)    0           concatenate_115[0][0]            \n",
      "                                                                 dropout_92[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 8, 8, 162)    648         concatenate_116[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 8, 8, 162)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 8, 8, 27)     39366       activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_93 (Dropout)            (None, 8, 8, 27)     0           conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_117 (Concatenate)   (None, 8, 8, 189)    0           concatenate_116[0][0]            \n",
      "                                                                 dropout_93[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 8, 8, 189)    756         concatenate_117[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 8, 8, 189)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 8, 8, 27)     45927       activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_94 (Dropout)            (None, 8, 8, 27)     0           conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_118 (Concatenate)   (None, 8, 8, 216)    0           concatenate_117[0][0]            \n",
      "                                                                 dropout_94[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 8, 8, 216)    864         concatenate_118[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 8, 8, 216)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 8, 8, 27)     52488       activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_95 (Dropout)            (None, 8, 8, 27)     0           conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_119 (Concatenate)   (None, 8, 8, 243)    0           concatenate_118[0][0]            \n",
      "                                                                 dropout_95[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 8, 8, 243)    972         concatenate_119[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 8, 8, 243)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 8, 8, 27)     6561        activation_134[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_96 (Dropout)            (None, 8, 8, 27)     0           conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_14 (AveragePo (None, 4, 4, 27)     0           dropout_96[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 4, 4, 27)     108         average_pooling2d_14[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 4, 4, 27)     0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 4, 4, 27)     6561        activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_97 (Dropout)            (None, 4, 4, 27)     0           conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_120 (Concatenate)   (None, 4, 4, 54)     0           average_pooling2d_14[0][0]       \n",
      "                                                                 dropout_97[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 4, 4, 54)     216         concatenate_120[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 4, 4, 54)     0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 4, 4, 27)     13122       activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_98 (Dropout)            (None, 4, 4, 27)     0           conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_121 (Concatenate)   (None, 4, 4, 81)     0           concatenate_120[0][0]            \n",
      "                                                                 dropout_98[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 4, 4, 81)     324         concatenate_121[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 4, 4, 81)     0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 4, 4, 27)     19683       activation_137[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_99 (Dropout)            (None, 4, 4, 27)     0           conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_122 (Concatenate)   (None, 4, 4, 108)    0           concatenate_121[0][0]            \n",
      "                                                                 dropout_99[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 4, 4, 108)    432         concatenate_122[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 4, 4, 108)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 4, 4, 27)     26244       activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_100 (Dropout)           (None, 4, 4, 27)     0           conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_123 (Concatenate)   (None, 4, 4, 135)    0           concatenate_122[0][0]            \n",
      "                                                                 dropout_100[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 4, 4, 135)    540         concatenate_123[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 4, 4, 135)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 4, 4, 27)     32805       activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_101 (Dropout)           (None, 4, 4, 27)     0           conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 4, 4, 162)    0           concatenate_123[0][0]            \n",
      "                                                                 dropout_101[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 4, 4, 162)    648         concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 4, 4, 162)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 4, 4, 27)     39366       activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_102 (Dropout)           (None, 4, 4, 27)     0           conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 4, 4, 189)    0           concatenate_124[0][0]            \n",
      "                                                                 dropout_102[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 4, 4, 189)    756         concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 4, 4, 189)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 4, 4, 27)     45927       activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_103 (Dropout)           (None, 4, 4, 27)     0           conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 4, 4, 216)    0           concatenate_125[0][0]            \n",
      "                                                                 dropout_103[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 4, 4, 216)    864         concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 4, 4, 216)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 4, 4, 27)     52488       activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_104 (Dropout)           (None, 4, 4, 27)     0           conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_127 (Concatenate)   (None, 4, 4, 243)    0           concatenate_126[0][0]            \n",
      "                                                                 dropout_104[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 4, 4, 243)    972         concatenate_127[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 4, 4, 243)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_15 (AveragePo (None, 2, 2, 243)    0           activation_143[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 984,231\n",
      "Trainable params: 974,511\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "**************************************after adding conv2d layer****************************************\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_13 (Functional)   (None, 2, 2, 243)         984231    \n",
      "_________________________________________________________________\n",
      "conv2d_146 (Conv2D)          (None, 1, 1, 10)          9730      \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "_________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Epoch 1/10\n",
      "391/391 [==============================] - 71s 182ms/step - loss: 1.5459 - accuracy: 0.4322 - val_loss: 1.3209 - val_accuracy: 0.5457\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 72s 184ms/step - loss: 1.0373 - accuracy: 0.6293 - val_loss: 1.8431 - val_accuracy: 0.5328\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 0.8413 - accuracy: 0.7024 - val_loss: 0.8697 - val_accuracy: 0.7013\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.7266 - accuracy: 0.7434 - val_loss: 1.4639 - val_accuracy: 0.6153\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.6387 - accuracy: 0.7769 - val_loss: 0.7149 - val_accuracy: 0.7654\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.5828 - accuracy: 0.7957 - val_loss: 0.6961 - val_accuracy: 0.7709\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.5299 - accuracy: 0.8153 - val_loss: 0.5709 - val_accuracy: 0.8055\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.4907 - accuracy: 0.8284 - val_loss: 0.7061 - val_accuracy: 0.7735\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.4604 - accuracy: 0.8381 - val_loss: 0.4593 - val_accuracy: 0.8465\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.4344 - accuracy: 0.8475 - val_loss: 0.5066 - val_accuracy: 0.8405\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6867 - accuracy: 0.7968\n",
      "Test loss: 0.6866834163665771\n",
      "Test accuracy: 0.7968000173568726\n"
     ]
    }
   ],
   "source": [
    "bright_model=modell(X_train_bright,X_cv_bright,X_test_bright,y_train,y_cv,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image augumentation featurewise_std_normalization and featurewise_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGWHHXWi5DJ_"
   },
   "outputs": [],
   "source": [
    "# Reff https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "\n",
    "def stand(arr_imgs):\n",
    "\n",
    "      # convert to numpy array\n",
    "      d_ar = arr_imgs.copy()\n",
    "      \n",
    "      for i in tqdm(range(d_ar.shape[0]), position=0):\n",
    "          data = d_ar[i]\n",
    "          # expand dimension to one sample\n",
    "          samples =np. expand_dims(data, 0)\n",
    "          # create image data augmentation generator\n",
    "          datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
    "          # prepare iterator\n",
    "          it = datagen.flow(samples, batch_size=1)\n",
    "          # generate samples and plot\n",
    "          # define subplot\n",
    "          # pyplot.subplot(330 + 1 + i)\n",
    "          # generate batch of images\n",
    "          #for j in range(9):\n",
    "          batch = it.next()     \n",
    "              #if j == 0:\n",
    "\n",
    "                  # convert to unsigned integers for viewing\n",
    "          image = batch[0].astype('uint8')\n",
    "          d_ar[i] = image\n",
    "                  # plot raw pixel data\n",
    "                  #break\n",
    "      return d_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "id": "dHEZ9fAF7OgB",
    "outputId": "acc59549-1265-4954-f107-22a7ca812e57"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "100%|██████████| 50000/50000 [00:11<00:00, 4526.63it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4578.85it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4306.21it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_stand=stand(X_train)\n",
    "X_cv_stand=stand(X_cv)\n",
    "X_test_stand=stand(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "6eX8dwrT7tH6",
    "outputId": "abca8bb1-3d9f-4f85-dee3-6593d23d0c13",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 32, 32, 27)   324         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 32, 32, 27)   108         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 32, 32, 27)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 32, 32, 27)   6561        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 32, 32, 27)   0           conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 32, 32, 54)   0           conv2d_147[0][0]                 \n",
      "                                                                 dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 32, 32, 54)   216         concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 32, 32, 54)   0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 32, 32, 27)   13122       activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 32, 32, 27)   0           conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 32, 32, 81)   0           concatenate_128[0][0]            \n",
      "                                                                 dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 32, 32, 81)   324         concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 32, 32, 81)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 32, 32, 27)   19683       activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 32, 32, 27)   0           conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 32, 32, 108)  0           concatenate_129[0][0]            \n",
      "                                                                 dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 32, 32, 108)  432         concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 32, 32, 108)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 32, 32, 27)   26244       activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 32, 32, 27)   0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 32, 32, 135)  0           concatenate_130[0][0]            \n",
      "                                                                 dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 32, 32, 135)  540         concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 32, 32, 135)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 32, 32, 27)   32805       activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 32, 32, 27)   0           conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 32, 32, 162)  0           concatenate_131[0][0]            \n",
      "                                                                 dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 32, 32, 162)  648         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 32, 32, 162)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 32, 32, 27)   39366       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 32, 32, 27)   0           conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 32, 32, 189)  0           concatenate_132[0][0]            \n",
      "                                                                 dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 32, 32, 189)  756         concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 32, 32, 189)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 32, 32, 27)   45927       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 32, 32, 27)   0           conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 32, 32, 216)  0           concatenate_133[0][0]            \n",
      "                                                                 dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 32, 32, 216)  864         concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 32, 32, 216)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 32, 32, 27)   52488       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 32, 32, 27)   0           conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 32, 32, 243)  0           concatenate_134[0][0]            \n",
      "                                                                 dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 32, 32, 243)  972         concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 32, 32, 243)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 32, 32, 27)   6561        activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 32, 32, 27)   0           conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 16, 16, 27)   0           dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 16, 16, 27)   108         average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 16, 16, 27)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 16, 16, 27)   6561        activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 16, 16, 27)   0           conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 16, 16, 54)   0           average_pooling2d_16[0][0]       \n",
      "                                                                 dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 16, 16, 54)   216         concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 16, 16, 54)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 16, 16, 27)   13122       activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 16, 16, 27)   0           conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 16, 16, 81)   0           concatenate_136[0][0]            \n",
      "                                                                 dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 16, 16, 81)   324         concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 16, 16, 81)   0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 16, 16, 27)   19683       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 16, 16, 27)   0           conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 16, 16, 108)  0           concatenate_137[0][0]            \n",
      "                                                                 dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 16, 16, 108)  432         concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 16, 16, 108)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 16, 16, 27)   26244       activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 16, 16, 27)   0           conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 16, 16, 135)  0           concatenate_138[0][0]            \n",
      "                                                                 dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 16, 16, 135)  540         concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 16, 16, 135)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 16, 16, 27)   32805       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 16, 16, 27)   0           conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 16, 16, 162)  0           concatenate_139[0][0]            \n",
      "                                                                 dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 16, 16, 162)  648         concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 16, 16, 162)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 16, 16, 27)   39366       activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 16, 16, 27)   0           conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 16, 16, 189)  0           concatenate_140[0][0]            \n",
      "                                                                 dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 16, 16, 189)  756         concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 16, 16, 189)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 16, 16, 27)   45927       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 16, 16, 27)   0           conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 16, 16, 216)  0           concatenate_141[0][0]            \n",
      "                                                                 dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 16, 16, 216)  864         concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 16, 16, 216)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 16, 16, 27)   52488       activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 16, 16, 27)   0           conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 16, 16, 243)  0           concatenate_142[0][0]            \n",
      "                                                                 dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 16, 16, 243)  972         concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 16, 16, 243)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 16, 16, 27)   6561        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 16, 16, 27)   0           conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 8, 8, 27)     0           dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 8, 8, 27)     108         average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 8, 8, 27)     0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 27)     6561        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 8, 8, 27)     0           conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 8, 8, 54)     0           average_pooling2d_17[0][0]       \n",
      "                                                                 dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 8, 8, 54)     216         concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 8, 8, 54)     0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 27)     13122       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 8, 8, 27)     0           conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 8, 8, 81)     0           concatenate_144[0][0]            \n",
      "                                                                 dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 8, 8, 81)     324         concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 8, 8, 81)     0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 27)     19683       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 8, 8, 27)     0           conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 8, 8, 108)    0           concatenate_145[0][0]            \n",
      "                                                                 dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 8, 8, 108)    432         concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 8, 8, 108)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 27)     26244       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)           (None, 8, 8, 27)     0           conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_147 (Concatenate)   (None, 8, 8, 135)    0           concatenate_146[0][0]            \n",
      "                                                                 dropout_126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 135)    540         concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 135)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 27)     32805       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)           (None, 8, 8, 27)     0           conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_148 (Concatenate)   (None, 8, 8, 162)    0           concatenate_147[0][0]            \n",
      "                                                                 dropout_127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 8, 8, 162)    648         concatenate_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 8, 8, 162)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 27)     39366       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)           (None, 8, 8, 27)     0           conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_149 (Concatenate)   (None, 8, 8, 189)    0           concatenate_148[0][0]            \n",
      "                                                                 dropout_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 8, 8, 189)    756         concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 8, 8, 189)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 27)     45927       activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 8, 8, 27)     0           conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 8, 8, 216)    0           concatenate_149[0][0]            \n",
      "                                                                 dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 8, 8, 216)    864         concatenate_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 216)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 27)     52488       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)           (None, 8, 8, 27)     0           conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 8, 8, 243)    0           concatenate_150[0][0]            \n",
      "                                                                 dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 243)    972         concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 243)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 27)     6561        activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 8, 8, 27)     0           conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 4, 4, 27)     0           dropout_131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 4, 4, 27)     108         average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 4, 4, 27)     0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 4, 4, 27)     6561        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)           (None, 4, 4, 27)     0           conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 4, 4, 54)     0           average_pooling2d_18[0][0]       \n",
      "                                                                 dropout_132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 4, 4, 54)     216         concatenate_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 4, 4, 54)     0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 4, 4, 27)     13122       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)           (None, 4, 4, 27)     0           conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_153 (Concatenate)   (None, 4, 4, 81)     0           concatenate_152[0][0]            \n",
      "                                                                 dropout_133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 4, 4, 81)     324         concatenate_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 4, 4, 81)     0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 4, 4, 27)     19683       activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)           (None, 4, 4, 27)     0           conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_154 (Concatenate)   (None, 4, 4, 108)    0           concatenate_153[0][0]            \n",
      "                                                                 dropout_134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 4, 4, 108)    432         concatenate_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 4, 4, 108)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 4, 4, 27)     26244       activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)           (None, 4, 4, 27)     0           conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_155 (Concatenate)   (None, 4, 4, 135)    0           concatenate_154[0][0]            \n",
      "                                                                 dropout_135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 4, 4, 135)    540         concatenate_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 4, 4, 135)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 4, 4, 27)     32805       activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 4, 4, 27)     0           conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 4, 4, 162)    0           concatenate_155[0][0]            \n",
      "                                                                 dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 4, 4, 162)    648         concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 4, 4, 162)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 4, 4, 27)     39366       activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 4, 4, 27)     0           conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 4, 4, 189)    0           concatenate_156[0][0]            \n",
      "                                                                 dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 4, 4, 189)    756         concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 4, 4, 189)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 4, 4, 27)     45927       activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 4, 4, 27)     0           conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 4, 4, 216)    0           concatenate_157[0][0]            \n",
      "                                                                 dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 4, 4, 216)    864         concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 4, 4, 216)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 4, 4, 27)     52488       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 4, 4, 27)     0           conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_159 (Concatenate)   (None, 4, 4, 243)    0           concatenate_158[0][0]            \n",
      "                                                                 dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 4, 4, 243)    972         concatenate_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 4, 4, 243)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 2, 2, 243)    0           activation_179[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 972)          0           average_pooling2d_19[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           9730        flatten_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "*************************************after removing last dense layer******************************************\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Model: \"functional_17\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_147 (Conv2D)             (None, 32, 32, 27)   324         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 32, 32, 27)   108         conv2d_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 32, 32, 27)   0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_148 (Conv2D)             (None, 32, 32, 27)   6561        activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_105 (Dropout)           (None, 32, 32, 27)   0           conv2d_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_128 (Concatenate)   (None, 32, 32, 54)   0           conv2d_147[0][0]                 \n",
      "                                                                 dropout_105[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 32, 32, 54)   216         concatenate_128[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 32, 32, 54)   0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_149 (Conv2D)             (None, 32, 32, 27)   13122       activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_106 (Dropout)           (None, 32, 32, 27)   0           conv2d_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_129 (Concatenate)   (None, 32, 32, 81)   0           concatenate_128[0][0]            \n",
      "                                                                 dropout_106[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_146 (BatchN (None, 32, 32, 81)   324         concatenate_129[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 32, 32, 81)   0           batch_normalization_146[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_150 (Conv2D)             (None, 32, 32, 27)   19683       activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_107 (Dropout)           (None, 32, 32, 27)   0           conv2d_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_130 (Concatenate)   (None, 32, 32, 108)  0           concatenate_129[0][0]            \n",
      "                                                                 dropout_107[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_147 (BatchN (None, 32, 32, 108)  432         concatenate_130[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 32, 32, 108)  0           batch_normalization_147[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_151 (Conv2D)             (None, 32, 32, 27)   26244       activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_108 (Dropout)           (None, 32, 32, 27)   0           conv2d_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_131 (Concatenate)   (None, 32, 32, 135)  0           concatenate_130[0][0]            \n",
      "                                                                 dropout_108[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_148 (BatchN (None, 32, 32, 135)  540         concatenate_131[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 32, 32, 135)  0           batch_normalization_148[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_152 (Conv2D)             (None, 32, 32, 27)   32805       activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_109 (Dropout)           (None, 32, 32, 27)   0           conv2d_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_132 (Concatenate)   (None, 32, 32, 162)  0           concatenate_131[0][0]            \n",
      "                                                                 dropout_109[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_149 (BatchN (None, 32, 32, 162)  648         concatenate_132[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 32, 32, 162)  0           batch_normalization_149[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_153 (Conv2D)             (None, 32, 32, 27)   39366       activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_110 (Dropout)           (None, 32, 32, 27)   0           conv2d_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_133 (Concatenate)   (None, 32, 32, 189)  0           concatenate_132[0][0]            \n",
      "                                                                 dropout_110[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_150 (BatchN (None, 32, 32, 189)  756         concatenate_133[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 32, 32, 189)  0           batch_normalization_150[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_154 (Conv2D)             (None, 32, 32, 27)   45927       activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_111 (Dropout)           (None, 32, 32, 27)   0           conv2d_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_134 (Concatenate)   (None, 32, 32, 216)  0           concatenate_133[0][0]            \n",
      "                                                                 dropout_111[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_151 (BatchN (None, 32, 32, 216)  864         concatenate_134[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 32, 32, 216)  0           batch_normalization_151[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_155 (Conv2D)             (None, 32, 32, 27)   52488       activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_112 (Dropout)           (None, 32, 32, 27)   0           conv2d_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_135 (Concatenate)   (None, 32, 32, 243)  0           concatenate_134[0][0]            \n",
      "                                                                 dropout_112[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_152 (BatchN (None, 32, 32, 243)  972         concatenate_135[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 32, 32, 243)  0           batch_normalization_152[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_156 (Conv2D)             (None, 32, 32, 27)   6561        activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_113 (Dropout)           (None, 32, 32, 27)   0           conv2d_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 16, 16, 27)   0           dropout_113[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_153 (BatchN (None, 16, 16, 27)   108         average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 16, 16, 27)   0           batch_normalization_153[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_157 (Conv2D)             (None, 16, 16, 27)   6561        activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_114 (Dropout)           (None, 16, 16, 27)   0           conv2d_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_136 (Concatenate)   (None, 16, 16, 54)   0           average_pooling2d_16[0][0]       \n",
      "                                                                 dropout_114[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_154 (BatchN (None, 16, 16, 54)   216         concatenate_136[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 16, 16, 54)   0           batch_normalization_154[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_158 (Conv2D)             (None, 16, 16, 27)   13122       activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_115 (Dropout)           (None, 16, 16, 27)   0           conv2d_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_137 (Concatenate)   (None, 16, 16, 81)   0           concatenate_136[0][0]            \n",
      "                                                                 dropout_115[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_155 (BatchN (None, 16, 16, 81)   324         concatenate_137[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 16, 16, 81)   0           batch_normalization_155[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_159 (Conv2D)             (None, 16, 16, 27)   19683       activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_116 (Dropout)           (None, 16, 16, 27)   0           conv2d_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_138 (Concatenate)   (None, 16, 16, 108)  0           concatenate_137[0][0]            \n",
      "                                                                 dropout_116[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_156 (BatchN (None, 16, 16, 108)  432         concatenate_138[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 16, 16, 108)  0           batch_normalization_156[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_160 (Conv2D)             (None, 16, 16, 27)   26244       activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_117 (Dropout)           (None, 16, 16, 27)   0           conv2d_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_139 (Concatenate)   (None, 16, 16, 135)  0           concatenate_138[0][0]            \n",
      "                                                                 dropout_117[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_157 (BatchN (None, 16, 16, 135)  540         concatenate_139[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 16, 16, 135)  0           batch_normalization_157[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_161 (Conv2D)             (None, 16, 16, 27)   32805       activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_118 (Dropout)           (None, 16, 16, 27)   0           conv2d_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_140 (Concatenate)   (None, 16, 16, 162)  0           concatenate_139[0][0]            \n",
      "                                                                 dropout_118[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_158 (BatchN (None, 16, 16, 162)  648         concatenate_140[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 16, 16, 162)  0           batch_normalization_158[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_162 (Conv2D)             (None, 16, 16, 27)   39366       activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_119 (Dropout)           (None, 16, 16, 27)   0           conv2d_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_141 (Concatenate)   (None, 16, 16, 189)  0           concatenate_140[0][0]            \n",
      "                                                                 dropout_119[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_159 (BatchN (None, 16, 16, 189)  756         concatenate_141[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 16, 16, 189)  0           batch_normalization_159[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_163 (Conv2D)             (None, 16, 16, 27)   45927       activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_120 (Dropout)           (None, 16, 16, 27)   0           conv2d_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_142 (Concatenate)   (None, 16, 16, 216)  0           concatenate_141[0][0]            \n",
      "                                                                 dropout_120[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_160 (BatchN (None, 16, 16, 216)  864         concatenate_142[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 16, 16, 216)  0           batch_normalization_160[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_164 (Conv2D)             (None, 16, 16, 27)   52488       activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_121 (Dropout)           (None, 16, 16, 27)   0           conv2d_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_143 (Concatenate)   (None, 16, 16, 243)  0           concatenate_142[0][0]            \n",
      "                                                                 dropout_121[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_161 (BatchN (None, 16, 16, 243)  972         concatenate_143[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 16, 16, 243)  0           batch_normalization_161[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_165 (Conv2D)             (None, 16, 16, 27)   6561        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_122 (Dropout)           (None, 16, 16, 27)   0           conv2d_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 8, 8, 27)     0           dropout_122[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_162 (BatchN (None, 8, 8, 27)     108         average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 8, 8, 27)     0           batch_normalization_162[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_166 (Conv2D)             (None, 8, 8, 27)     6561        activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_123 (Dropout)           (None, 8, 8, 27)     0           conv2d_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_144 (Concatenate)   (None, 8, 8, 54)     0           average_pooling2d_17[0][0]       \n",
      "                                                                 dropout_123[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_163 (BatchN (None, 8, 8, 54)     216         concatenate_144[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 8, 8, 54)     0           batch_normalization_163[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_167 (Conv2D)             (None, 8, 8, 27)     13122       activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_124 (Dropout)           (None, 8, 8, 27)     0           conv2d_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_145 (Concatenate)   (None, 8, 8, 81)     0           concatenate_144[0][0]            \n",
      "                                                                 dropout_124[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_164 (BatchN (None, 8, 8, 81)     324         concatenate_145[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 8, 8, 81)     0           batch_normalization_164[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_168 (Conv2D)             (None, 8, 8, 27)     19683       activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_125 (Dropout)           (None, 8, 8, 27)     0           conv2d_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_146 (Concatenate)   (None, 8, 8, 108)    0           concatenate_145[0][0]            \n",
      "                                                                 dropout_125[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_165 (BatchN (None, 8, 8, 108)    432         concatenate_146[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 8, 8, 108)    0           batch_normalization_165[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_169 (Conv2D)             (None, 8, 8, 27)     26244       activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_126 (Dropout)           (None, 8, 8, 27)     0           conv2d_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_147 (Concatenate)   (None, 8, 8, 135)    0           concatenate_146[0][0]            \n",
      "                                                                 dropout_126[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_166 (BatchN (None, 8, 8, 135)    540         concatenate_147[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 8, 8, 135)    0           batch_normalization_166[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_170 (Conv2D)             (None, 8, 8, 27)     32805       activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_127 (Dropout)           (None, 8, 8, 27)     0           conv2d_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_148 (Concatenate)   (None, 8, 8, 162)    0           concatenate_147[0][0]            \n",
      "                                                                 dropout_127[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_167 (BatchN (None, 8, 8, 162)    648         concatenate_148[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 8, 8, 162)    0           batch_normalization_167[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_171 (Conv2D)             (None, 8, 8, 27)     39366       activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_128 (Dropout)           (None, 8, 8, 27)     0           conv2d_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_149 (Concatenate)   (None, 8, 8, 189)    0           concatenate_148[0][0]            \n",
      "                                                                 dropout_128[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_168 (BatchN (None, 8, 8, 189)    756         concatenate_149[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 8, 8, 189)    0           batch_normalization_168[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_172 (Conv2D)             (None, 8, 8, 27)     45927       activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_129 (Dropout)           (None, 8, 8, 27)     0           conv2d_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_150 (Concatenate)   (None, 8, 8, 216)    0           concatenate_149[0][0]            \n",
      "                                                                 dropout_129[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_169 (BatchN (None, 8, 8, 216)    864         concatenate_150[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 8, 8, 216)    0           batch_normalization_169[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_173 (Conv2D)             (None, 8, 8, 27)     52488       activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_130 (Dropout)           (None, 8, 8, 27)     0           conv2d_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_151 (Concatenate)   (None, 8, 8, 243)    0           concatenate_150[0][0]            \n",
      "                                                                 dropout_130[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_170 (BatchN (None, 8, 8, 243)    972         concatenate_151[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 8, 8, 243)    0           batch_normalization_170[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_174 (Conv2D)             (None, 8, 8, 27)     6561        activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_131 (Dropout)           (None, 8, 8, 27)     0           conv2d_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 4, 4, 27)     0           dropout_131[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_171 (BatchN (None, 4, 4, 27)     108         average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 4, 4, 27)     0           batch_normalization_171[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_175 (Conv2D)             (None, 4, 4, 27)     6561        activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_132 (Dropout)           (None, 4, 4, 27)     0           conv2d_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_152 (Concatenate)   (None, 4, 4, 54)     0           average_pooling2d_18[0][0]       \n",
      "                                                                 dropout_132[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_172 (BatchN (None, 4, 4, 54)     216         concatenate_152[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 4, 4, 54)     0           batch_normalization_172[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_176 (Conv2D)             (None, 4, 4, 27)     13122       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_133 (Dropout)           (None, 4, 4, 27)     0           conv2d_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_153 (Concatenate)   (None, 4, 4, 81)     0           concatenate_152[0][0]            \n",
      "                                                                 dropout_133[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_173 (BatchN (None, 4, 4, 81)     324         concatenate_153[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 4, 4, 81)     0           batch_normalization_173[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_177 (Conv2D)             (None, 4, 4, 27)     19683       activation_173[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_134 (Dropout)           (None, 4, 4, 27)     0           conv2d_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_154 (Concatenate)   (None, 4, 4, 108)    0           concatenate_153[0][0]            \n",
      "                                                                 dropout_134[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_174 (BatchN (None, 4, 4, 108)    432         concatenate_154[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 4, 4, 108)    0           batch_normalization_174[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_178 (Conv2D)             (None, 4, 4, 27)     26244       activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_135 (Dropout)           (None, 4, 4, 27)     0           conv2d_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_155 (Concatenate)   (None, 4, 4, 135)    0           concatenate_154[0][0]            \n",
      "                                                                 dropout_135[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_175 (BatchN (None, 4, 4, 135)    540         concatenate_155[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 4, 4, 135)    0           batch_normalization_175[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_179 (Conv2D)             (None, 4, 4, 27)     32805       activation_175[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_136 (Dropout)           (None, 4, 4, 27)     0           conv2d_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_156 (Concatenate)   (None, 4, 4, 162)    0           concatenate_155[0][0]            \n",
      "                                                                 dropout_136[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_176 (BatchN (None, 4, 4, 162)    648         concatenate_156[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 4, 4, 162)    0           batch_normalization_176[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_180 (Conv2D)             (None, 4, 4, 27)     39366       activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_137 (Dropout)           (None, 4, 4, 27)     0           conv2d_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_157 (Concatenate)   (None, 4, 4, 189)    0           concatenate_156[0][0]            \n",
      "                                                                 dropout_137[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_177 (BatchN (None, 4, 4, 189)    756         concatenate_157[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 4, 4, 189)    0           batch_normalization_177[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_181 (Conv2D)             (None, 4, 4, 27)     45927       activation_177[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_138 (Dropout)           (None, 4, 4, 27)     0           conv2d_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_158 (Concatenate)   (None, 4, 4, 216)    0           concatenate_157[0][0]            \n",
      "                                                                 dropout_138[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_178 (BatchN (None, 4, 4, 216)    864         concatenate_158[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 4, 4, 216)    0           batch_normalization_178[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_182 (Conv2D)             (None, 4, 4, 27)     52488       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_139 (Dropout)           (None, 4, 4, 27)     0           conv2d_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_159 (Concatenate)   (None, 4, 4, 243)    0           concatenate_158[0][0]            \n",
      "                                                                 dropout_139[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_179 (BatchN (None, 4, 4, 243)    972         concatenate_159[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 4, 4, 243)    0           batch_normalization_179[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_19 (AveragePo (None, 2, 2, 243)    0           activation_179[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 984,231\n",
      "Trainable params: 974,511\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "**************************************after adding conv2d layer****************************************\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_17 (Functional)   (None, 2, 2, 243)         984231    \n",
      "_________________________________________________________________\n",
      "conv2d_183 (Conv2D)          (None, 1, 1, 10)          9730      \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "_________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Epoch 1/10\n",
      "  2/391 [..............................] - ETA: 1:04 - loss: 2.4377 - accuracy: 0.1055WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0652s vs `on_train_batch_end` time: 0.1072s). Check your callbacks.\n",
      "391/391 [==============================] - 71s 182ms/step - loss: 1.4240 - accuracy: 0.4759 - val_loss: 1.7229 - val_accuracy: 0.4057\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 72s 184ms/step - loss: 0.9675 - accuracy: 0.6535 - val_loss: 1.3753 - val_accuracy: 0.5740\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 0.7972 - accuracy: 0.7160 - val_loss: 1.5148 - val_accuracy: 0.5801\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.6827 - accuracy: 0.7592 - val_loss: 0.9606 - val_accuracy: 0.6914\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.6128 - accuracy: 0.7846 - val_loss: 0.8330 - val_accuracy: 0.7385\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.5526 - accuracy: 0.8058 - val_loss: 0.8679 - val_accuracy: 0.7347\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.5095 - accuracy: 0.8211 - val_loss: 0.8415 - val_accuracy: 0.7274\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 73s 187ms/step - loss: 0.4664 - accuracy: 0.8361 - val_loss: 0.5420 - val_accuracy: 0.8235\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.4386 - accuracy: 0.8453 - val_loss: 1.0687 - val_accuracy: 0.7146\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.4082 - accuracy: 0.8575 - val_loss: 0.4853 - val_accuracy: 0.8381\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.6650 - accuracy: 0.7972\n",
      "Test loss: 0.6649559140205383\n",
      "Test accuracy: 0.7972000241279602\n"
     ]
    }
   ],
   "source": [
    "bright_model=modell(X_train_stand,X_cv_stand,X_test_stand,y_train,y_cv,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFdHRlbv8OJJ"
   },
   "source": [
    "## image augumentation zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "snO4Xit69pvG"
   },
   "outputs": [],
   "source": [
    "# Reff https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/\n",
    "\n",
    "def zoom(arr_imgs):\n",
    "\n",
    "      # convert to numpy array\n",
    "      d_ar = arr_imgs.copy()\n",
    "      \n",
    "      for i in tqdm(range(d_ar.shape[0]), position=0):\n",
    "          data = d_ar[i]\n",
    "          # expand dimension to one sample\n",
    "          samples = expand_dims(data, 0)\n",
    "          # create image data augmentation generator\n",
    "          datagen = ImageDataGenerator(zoom_range=[0.5,1.0])\n",
    "          # prepare iterator\n",
    "          it = datagen.flow(samples, batch_size=1)\n",
    "          # generate samples and plot\n",
    "          # define subplot\n",
    "          # pyplot.subplot(330 + 1 + i)\n",
    "          # generate batch of images\n",
    "          #for j in range(9):\n",
    "          batch = it.next()     \n",
    "              #if j == 0:\n",
    "\n",
    "                  # convert to unsigned integers for viewing\n",
    "          image = batch[0].astype('uint8')\n",
    "          d_ar[i] = image\n",
    "                  # plot raw pixel data\n",
    "                  #break\n",
    "      return d_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165
    },
    "colab_type": "code",
    "id": "QMkiPSOv9qMQ",
    "outputId": "901c3021-0e02-47fb-c8d1-b88aab75abd3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50000 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "100%|██████████| 50000/50000 [00:11<00:00, 4501.82it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4436.12it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 4450.79it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_zoom=stand(X_train)\n",
    "X_cv_zoom=stand(X_cv)\n",
    "X_test_zoom=stand(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rDxz7RT1-E4K",
    "outputId": "16baaa05-8edc-4605-aa46-863fefadf019",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_19\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 32, 32, 27)   324         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 32, 32, 27)   108         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 32, 32, 27)   0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 32, 32, 27)   6561        activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 32, 32, 27)   0           conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_160 (Concatenate)   (None, 32, 32, 54)   0           conv2d_184[0][0]                 \n",
      "                                                                 dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 32, 32, 54)   216         concatenate_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 32, 32, 54)   0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 32, 32, 27)   13122       activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, 32, 32, 27)   0           conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_161 (Concatenate)   (None, 32, 32, 81)   0           concatenate_160[0][0]            \n",
      "                                                                 dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 32, 32, 81)   324         concatenate_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 32, 32, 81)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 32, 32, 27)   19683       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, 32, 32, 27)   0           conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_162 (Concatenate)   (None, 32, 32, 108)  0           concatenate_161[0][0]            \n",
      "                                                                 dropout_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 32, 32, 108)  432         concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 32, 32, 108)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 32, 32, 27)   26244       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, 32, 32, 27)   0           conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_163 (Concatenate)   (None, 32, 32, 135)  0           concatenate_162[0][0]            \n",
      "                                                                 dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 32, 32, 135)  540         concatenate_163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 32, 32, 135)  0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 32, 32, 27)   32805       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 32, 32, 27)   0           conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_164 (Concatenate)   (None, 32, 32, 162)  0           concatenate_163[0][0]            \n",
      "                                                                 dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 32, 32, 162)  648         concatenate_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 32, 32, 162)  0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 32, 32, 27)   39366       activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, 32, 32, 27)   0           conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_165 (Concatenate)   (None, 32, 32, 189)  0           concatenate_164[0][0]            \n",
      "                                                                 dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 32, 32, 189)  756         concatenate_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 32, 32, 189)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 32, 32, 27)   45927       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 32, 32, 27)   0           conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_166 (Concatenate)   (None, 32, 32, 216)  0           concatenate_165[0][0]            \n",
      "                                                                 dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 32, 32, 216)  864         concatenate_166[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 32, 32, 216)  0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 32, 32, 27)   52488       activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, 32, 32, 27)   0           conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_167 (Concatenate)   (None, 32, 32, 243)  0           concatenate_166[0][0]            \n",
      "                                                                 dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 32, 32, 243)  972         concatenate_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 32, 32, 243)  0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 32, 32, 27)   6561        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 32, 32, 27)   0           conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 27)   0           dropout_148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 16, 16, 27)   108         average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 16, 16, 27)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 27)   6561        activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, 16, 16, 27)   0           conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_168 (Concatenate)   (None, 16, 16, 54)   0           average_pooling2d_20[0][0]       \n",
      "                                                                 dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 16, 16, 54)   216         concatenate_168[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 16, 16, 54)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 27)   13122       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 16, 16, 27)   0           conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_169 (Concatenate)   (None, 16, 16, 81)   0           concatenate_168[0][0]            \n",
      "                                                                 dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 16, 16, 81)   324         concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 16, 16, 81)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 27)   19683       activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, 16, 16, 27)   0           conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_170 (Concatenate)   (None, 16, 16, 108)  0           concatenate_169[0][0]            \n",
      "                                                                 dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 16, 16, 108)  432         concatenate_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 16, 16, 108)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 27)   26244       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 16, 16, 27)   0           conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_171 (Concatenate)   (None, 16, 16, 135)  0           concatenate_170[0][0]            \n",
      "                                                                 dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 135)  540         concatenate_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 135)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 27)   32805       activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, 16, 16, 27)   0           conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_172 (Concatenate)   (None, 16, 16, 162)  0           concatenate_171[0][0]            \n",
      "                                                                 dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 162)  648         concatenate_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 162)  0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 27)   39366       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 16, 16, 27)   0           conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_173 (Concatenate)   (None, 16, 16, 189)  0           concatenate_172[0][0]            \n",
      "                                                                 dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 189)  756         concatenate_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 189)  0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 27)   45927       activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, 16, 16, 27)   0           conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_174 (Concatenate)   (None, 16, 16, 216)  0           concatenate_173[0][0]            \n",
      "                                                                 dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 216)  864         concatenate_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 216)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 27)   52488       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 16, 16, 27)   0           conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)   (None, 16, 16, 243)  0           concatenate_174[0][0]            \n",
      "                                                                 dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 243)  972         concatenate_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 243)  0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 27)   6561        activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, 16, 16, 27)   0           conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 8, 8, 27)     0           dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 8, 8, 27)     108         average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 8, 8, 27)     0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 8, 8, 27)     6561        activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, 8, 8, 27)     0           conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_176 (Concatenate)   (None, 8, 8, 54)     0           average_pooling2d_21[0][0]       \n",
      "                                                                 dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 8, 8, 54)     216         concatenate_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 8, 8, 54)     0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 8, 8, 27)     13122       activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, 8, 8, 27)     0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_177 (Concatenate)   (None, 8, 8, 81)     0           concatenate_176[0][0]            \n",
      "                                                                 dropout_159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 8, 8, 81)     324         concatenate_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 8, 8, 81)     0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 8, 8, 27)     19683       activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 8, 8, 27)     0           conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_178 (Concatenate)   (None, 8, 8, 108)    0           concatenate_177[0][0]            \n",
      "                                                                 dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 8, 8, 108)    432         concatenate_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 8, 8, 108)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 8, 8, 27)     26244       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, 8, 8, 27)     0           conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_179 (Concatenate)   (None, 8, 8, 135)    0           concatenate_178[0][0]            \n",
      "                                                                 dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 8, 8, 135)    540         concatenate_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 8, 8, 135)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 8, 8, 27)     32805       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 8, 8, 27)     0           conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_180 (Concatenate)   (None, 8, 8, 162)    0           concatenate_179[0][0]            \n",
      "                                                                 dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 8, 8, 162)    648         concatenate_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 8, 8, 162)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 8, 8, 27)     39366       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, 8, 8, 27)     0           conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_181 (Concatenate)   (None, 8, 8, 189)    0           concatenate_180[0][0]            \n",
      "                                                                 dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 8, 8, 189)    756         concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 8, 8, 189)    0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 8, 8, 27)     45927       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, 8, 8, 27)     0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_182 (Concatenate)   (None, 8, 8, 216)    0           concatenate_181[0][0]            \n",
      "                                                                 dropout_164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 8, 8, 216)    864         concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 8, 8, 216)    0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 8, 8, 27)     52488       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_165 (Dropout)           (None, 8, 8, 27)     0           conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_183 (Concatenate)   (None, 8, 8, 243)    0           concatenate_182[0][0]            \n",
      "                                                                 dropout_165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 8, 8, 243)    972         concatenate_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 8, 8, 243)    0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 8, 8, 27)     6561        activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_166 (Dropout)           (None, 8, 8, 27)     0           conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 4, 4, 27)     0           dropout_166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 4, 4, 27)     108         average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 4, 4, 27)     0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 4, 4, 27)     6561        activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)           (None, 4, 4, 27)     0           conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_184 (Concatenate)   (None, 4, 4, 54)     0           average_pooling2d_22[0][0]       \n",
      "                                                                 dropout_167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 4, 4, 54)     216         concatenate_184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 4, 4, 54)     0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 4, 4, 27)     13122       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)           (None, 4, 4, 27)     0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_185 (Concatenate)   (None, 4, 4, 81)     0           concatenate_184[0][0]            \n",
      "                                                                 dropout_168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 4, 4, 81)     324         concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 4, 4, 81)     0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 4, 4, 27)     19683       activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)           (None, 4, 4, 27)     0           conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_186 (Concatenate)   (None, 4, 4, 108)    0           concatenate_185[0][0]            \n",
      "                                                                 dropout_169[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 4, 4, 108)    432         concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 4, 4, 108)    0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 4, 4, 27)     26244       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)           (None, 4, 4, 27)     0           conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_187 (Concatenate)   (None, 4, 4, 135)    0           concatenate_186[0][0]            \n",
      "                                                                 dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 4, 4, 135)    540         concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 4, 4, 135)    0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 4, 4, 27)     32805       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 4, 4, 27)     0           conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_188 (Concatenate)   (None, 4, 4, 162)    0           concatenate_187[0][0]            \n",
      "                                                                 dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 4, 4, 162)    648         concatenate_188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 4, 4, 162)    0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 4, 4, 27)     39366       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 4, 4, 27)     0           conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_189 (Concatenate)   (None, 4, 4, 189)    0           concatenate_188[0][0]            \n",
      "                                                                 dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 4, 4, 189)    756         concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 4, 4, 189)    0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 4, 4, 27)     45927       activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 4, 4, 27)     0           conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_190 (Concatenate)   (None, 4, 4, 216)    0           concatenate_189[0][0]            \n",
      "                                                                 dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 4, 4, 216)    864         concatenate_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 4, 4, 216)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 4, 4, 27)     52488       activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 4, 4, 27)     0           conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_191 (Concatenate)   (None, 4, 4, 243)    0           concatenate_190[0][0]            \n",
      "                                                                 dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 4, 4, 243)    972         concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 4, 4, 243)    0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 2, 2, 243)    0           activation_215[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 972)          0           average_pooling2d_23[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           9730        flatten_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "*************************************after removing last dense layer******************************************\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Model: \"functional_21\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_184 (Conv2D)             (None, 32, 32, 27)   324         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_180 (BatchN (None, 32, 32, 27)   108         conv2d_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 32, 32, 27)   0           batch_normalization_180[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_185 (Conv2D)             (None, 32, 32, 27)   6561        activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_140 (Dropout)           (None, 32, 32, 27)   0           conv2d_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_160 (Concatenate)   (None, 32, 32, 54)   0           conv2d_184[0][0]                 \n",
      "                                                                 dropout_140[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_181 (BatchN (None, 32, 32, 54)   216         concatenate_160[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 32, 32, 54)   0           batch_normalization_181[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_186 (Conv2D)             (None, 32, 32, 27)   13122       activation_181[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_141 (Dropout)           (None, 32, 32, 27)   0           conv2d_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_161 (Concatenate)   (None, 32, 32, 81)   0           concatenate_160[0][0]            \n",
      "                                                                 dropout_141[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_182 (BatchN (None, 32, 32, 81)   324         concatenate_161[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 32, 32, 81)   0           batch_normalization_182[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_187 (Conv2D)             (None, 32, 32, 27)   19683       activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_142 (Dropout)           (None, 32, 32, 27)   0           conv2d_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_162 (Concatenate)   (None, 32, 32, 108)  0           concatenate_161[0][0]            \n",
      "                                                                 dropout_142[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_183 (BatchN (None, 32, 32, 108)  432         concatenate_162[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 32, 32, 108)  0           batch_normalization_183[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_188 (Conv2D)             (None, 32, 32, 27)   26244       activation_183[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_143 (Dropout)           (None, 32, 32, 27)   0           conv2d_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_163 (Concatenate)   (None, 32, 32, 135)  0           concatenate_162[0][0]            \n",
      "                                                                 dropout_143[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_184 (BatchN (None, 32, 32, 135)  540         concatenate_163[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 32, 32, 135)  0           batch_normalization_184[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_189 (Conv2D)             (None, 32, 32, 27)   32805       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_144 (Dropout)           (None, 32, 32, 27)   0           conv2d_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_164 (Concatenate)   (None, 32, 32, 162)  0           concatenate_163[0][0]            \n",
      "                                                                 dropout_144[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_185 (BatchN (None, 32, 32, 162)  648         concatenate_164[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 32, 32, 162)  0           batch_normalization_185[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_190 (Conv2D)             (None, 32, 32, 27)   39366       activation_185[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_145 (Dropout)           (None, 32, 32, 27)   0           conv2d_190[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_165 (Concatenate)   (None, 32, 32, 189)  0           concatenate_164[0][0]            \n",
      "                                                                 dropout_145[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_186 (BatchN (None, 32, 32, 189)  756         concatenate_165[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 32, 32, 189)  0           batch_normalization_186[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_191 (Conv2D)             (None, 32, 32, 27)   45927       activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_146 (Dropout)           (None, 32, 32, 27)   0           conv2d_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_166 (Concatenate)   (None, 32, 32, 216)  0           concatenate_165[0][0]            \n",
      "                                                                 dropout_146[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_187 (BatchN (None, 32, 32, 216)  864         concatenate_166[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_187 (Activation)     (None, 32, 32, 216)  0           batch_normalization_187[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 32, 32, 27)   52488       activation_187[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_147 (Dropout)           (None, 32, 32, 27)   0           conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_167 (Concatenate)   (None, 32, 32, 243)  0           concatenate_166[0][0]            \n",
      "                                                                 dropout_147[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_188 (BatchN (None, 32, 32, 243)  972         concatenate_167[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 32, 32, 243)  0           batch_normalization_188[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 32, 32, 27)   6561        activation_188[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_148 (Dropout)           (None, 32, 32, 27)   0           conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_20 (AveragePo (None, 16, 16, 27)   0           dropout_148[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_189 (BatchN (None, 16, 16, 27)   108         average_pooling2d_20[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 16, 16, 27)   0           batch_normalization_189[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 16, 16, 27)   6561        activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_149 (Dropout)           (None, 16, 16, 27)   0           conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_168 (Concatenate)   (None, 16, 16, 54)   0           average_pooling2d_20[0][0]       \n",
      "                                                                 dropout_149[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_190 (BatchN (None, 16, 16, 54)   216         concatenate_168[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 16, 16, 54)   0           batch_normalization_190[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 16, 16, 27)   13122       activation_190[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_150 (Dropout)           (None, 16, 16, 27)   0           conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_169 (Concatenate)   (None, 16, 16, 81)   0           concatenate_168[0][0]            \n",
      "                                                                 dropout_150[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_191 (BatchN (None, 16, 16, 81)   324         concatenate_169[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 16, 16, 81)   0           batch_normalization_191[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 16, 16, 27)   19683       activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_151 (Dropout)           (None, 16, 16, 27)   0           conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_170 (Concatenate)   (None, 16, 16, 108)  0           concatenate_169[0][0]            \n",
      "                                                                 dropout_151[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_192 (BatchN (None, 16, 16, 108)  432         concatenate_170[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 16, 16, 108)  0           batch_normalization_192[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 16, 16, 27)   26244       activation_192[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_152 (Dropout)           (None, 16, 16, 27)   0           conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_171 (Concatenate)   (None, 16, 16, 135)  0           concatenate_170[0][0]            \n",
      "                                                                 dropout_152[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_193 (BatchN (None, 16, 16, 135)  540         concatenate_171[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 16, 16, 135)  0           batch_normalization_193[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 16, 16, 27)   32805       activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_153 (Dropout)           (None, 16, 16, 27)   0           conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_172 (Concatenate)   (None, 16, 16, 162)  0           concatenate_171[0][0]            \n",
      "                                                                 dropout_153[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_194 (BatchN (None, 16, 16, 162)  648         concatenate_172[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 16, 16, 162)  0           batch_normalization_194[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 16, 16, 27)   39366       activation_194[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_154 (Dropout)           (None, 16, 16, 27)   0           conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_173 (Concatenate)   (None, 16, 16, 189)  0           concatenate_172[0][0]            \n",
      "                                                                 dropout_154[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_195 (BatchN (None, 16, 16, 189)  756         concatenate_173[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 16, 16, 189)  0           batch_normalization_195[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 16, 16, 27)   45927       activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_155 (Dropout)           (None, 16, 16, 27)   0           conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_174 (Concatenate)   (None, 16, 16, 216)  0           concatenate_173[0][0]            \n",
      "                                                                 dropout_155[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_196 (BatchN (None, 16, 16, 216)  864         concatenate_174[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 16, 16, 216)  0           batch_normalization_196[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 16, 16, 27)   52488       activation_196[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_156 (Dropout)           (None, 16, 16, 27)   0           conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_175 (Concatenate)   (None, 16, 16, 243)  0           concatenate_174[0][0]            \n",
      "                                                                 dropout_156[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_197 (BatchN (None, 16, 16, 243)  972         concatenate_175[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 16, 16, 243)  0           batch_normalization_197[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 16, 16, 27)   6561        activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_157 (Dropout)           (None, 16, 16, 27)   0           conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_21 (AveragePo (None, 8, 8, 27)     0           dropout_157[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 8, 8, 27)     108         average_pooling2d_21[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 8, 8, 27)     0           batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 8, 8, 27)     6561        activation_198[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_158 (Dropout)           (None, 8, 8, 27)     0           conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_176 (Concatenate)   (None, 8, 8, 54)     0           average_pooling2d_21[0][0]       \n",
      "                                                                 dropout_158[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 8, 8, 54)     216         concatenate_176[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 8, 8, 54)     0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 8, 8, 27)     13122       activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_159 (Dropout)           (None, 8, 8, 27)     0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_177 (Concatenate)   (None, 8, 8, 81)     0           concatenate_176[0][0]            \n",
      "                                                                 dropout_159[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 8, 8, 81)     324         concatenate_177[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 8, 8, 81)     0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 8, 8, 27)     19683       activation_200[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_160 (Dropout)           (None, 8, 8, 27)     0           conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_178 (Concatenate)   (None, 8, 8, 108)    0           concatenate_177[0][0]            \n",
      "                                                                 dropout_160[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 8, 8, 108)    432         concatenate_178[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 8, 8, 108)    0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 8, 8, 27)     26244       activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_161 (Dropout)           (None, 8, 8, 27)     0           conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_179 (Concatenate)   (None, 8, 8, 135)    0           concatenate_178[0][0]            \n",
      "                                                                 dropout_161[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 8, 8, 135)    540         concatenate_179[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 8, 8, 135)    0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 8, 8, 27)     32805       activation_202[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_162 (Dropout)           (None, 8, 8, 27)     0           conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_180 (Concatenate)   (None, 8, 8, 162)    0           concatenate_179[0][0]            \n",
      "                                                                 dropout_162[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 8, 8, 162)    648         concatenate_180[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 8, 8, 162)    0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 8, 8, 27)     39366       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_163 (Dropout)           (None, 8, 8, 27)     0           conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_181 (Concatenate)   (None, 8, 8, 189)    0           concatenate_180[0][0]            \n",
      "                                                                 dropout_163[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 8, 8, 189)    756         concatenate_181[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 8, 8, 189)    0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 8, 8, 27)     45927       activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_164 (Dropout)           (None, 8, 8, 27)     0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_182 (Concatenate)   (None, 8, 8, 216)    0           concatenate_181[0][0]            \n",
      "                                                                 dropout_164[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 8, 8, 216)    864         concatenate_182[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 8, 8, 216)    0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 8, 8, 27)     52488       activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_165 (Dropout)           (None, 8, 8, 27)     0           conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_183 (Concatenate)   (None, 8, 8, 243)    0           concatenate_182[0][0]            \n",
      "                                                                 dropout_165[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 8, 8, 243)    972         concatenate_183[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 8, 8, 243)    0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 8, 8, 27)     6561        activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_166 (Dropout)           (None, 8, 8, 27)     0           conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_22 (AveragePo (None, 4, 4, 27)     0           dropout_166[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 4, 4, 27)     108         average_pooling2d_22[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 4, 4, 27)     0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 4, 4, 27)     6561        activation_207[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_167 (Dropout)           (None, 4, 4, 27)     0           conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_184 (Concatenate)   (None, 4, 4, 54)     0           average_pooling2d_22[0][0]       \n",
      "                                                                 dropout_167[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 4, 4, 54)     216         concatenate_184[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 4, 4, 54)     0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 4, 4, 27)     13122       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_168 (Dropout)           (None, 4, 4, 27)     0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_185 (Concatenate)   (None, 4, 4, 81)     0           concatenate_184[0][0]            \n",
      "                                                                 dropout_168[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 4, 4, 81)     324         concatenate_185[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 4, 4, 81)     0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 4, 4, 27)     19683       activation_209[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_169 (Dropout)           (None, 4, 4, 27)     0           conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_186 (Concatenate)   (None, 4, 4, 108)    0           concatenate_185[0][0]            \n",
      "                                                                 dropout_169[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 4, 4, 108)    432         concatenate_186[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 4, 4, 108)    0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 4, 4, 27)     26244       activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_170 (Dropout)           (None, 4, 4, 27)     0           conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_187 (Concatenate)   (None, 4, 4, 135)    0           concatenate_186[0][0]            \n",
      "                                                                 dropout_170[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 4, 4, 135)    540         concatenate_187[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 4, 4, 135)    0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 4, 4, 27)     32805       activation_211[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_171 (Dropout)           (None, 4, 4, 27)     0           conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_188 (Concatenate)   (None, 4, 4, 162)    0           concatenate_187[0][0]            \n",
      "                                                                 dropout_171[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 4, 4, 162)    648         concatenate_188[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 4, 4, 162)    0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 4, 4, 27)     39366       activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_172 (Dropout)           (None, 4, 4, 27)     0           conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_189 (Concatenate)   (None, 4, 4, 189)    0           concatenate_188[0][0]            \n",
      "                                                                 dropout_172[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 4, 4, 189)    756         concatenate_189[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 4, 4, 189)    0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 4, 4, 27)     45927       activation_213[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_173 (Dropout)           (None, 4, 4, 27)     0           conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_190 (Concatenate)   (None, 4, 4, 216)    0           concatenate_189[0][0]            \n",
      "                                                                 dropout_173[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 4, 4, 216)    864         concatenate_190[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 4, 4, 216)    0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 4, 4, 27)     52488       activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_174 (Dropout)           (None, 4, 4, 27)     0           conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_191 (Concatenate)   (None, 4, 4, 243)    0           concatenate_190[0][0]            \n",
      "                                                                 dropout_174[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 4, 4, 243)    972         concatenate_191[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 4, 4, 243)    0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_23 (AveragePo (None, 2, 2, 243)    0           activation_215[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 984,231\n",
      "Trainable params: 974,511\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "**************************************after adding conv2d layer****************************************\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_21 (Functional)   (None, 2, 2, 243)         984231    \n",
      "_________________________________________________________________\n",
      "conv2d_220 (Conv2D)          (None, 1, 1, 10)          9730      \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "_________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Epoch 1/10\n",
      "  2/391 [..............................] - ETA: 1:00 - loss: 2.3922 - accuracy: 0.1133WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0640s vs `on_train_batch_end` time: 0.1125s). Check your callbacks.\n",
      "391/391 [==============================] - 70s 179ms/step - loss: 1.3927 - accuracy: 0.4891 - val_loss: 1.5167 - val_accuracy: 0.5319\n",
      "Epoch 2/10\n",
      "391/391 [==============================] - 71s 181ms/step - loss: 0.9652 - accuracy: 0.6538 - val_loss: 1.0307 - val_accuracy: 0.6496\n",
      "Epoch 3/10\n",
      "391/391 [==============================] - 72s 184ms/step - loss: 0.7936 - accuracy: 0.7197 - val_loss: 0.8697 - val_accuracy: 0.7135\n",
      "Epoch 4/10\n",
      "391/391 [==============================] - 72s 185ms/step - loss: 0.6904 - accuracy: 0.7550 - val_loss: 0.9004 - val_accuracy: 0.7335\n",
      "Epoch 5/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.6100 - accuracy: 0.7852 - val_loss: 0.6511 - val_accuracy: 0.7831\n",
      "Epoch 6/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.5501 - accuracy: 0.8064 - val_loss: 0.7025 - val_accuracy: 0.7700\n",
      "Epoch 7/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.5019 - accuracy: 0.8256 - val_loss: 0.7756 - val_accuracy: 0.7644\n",
      "Epoch 8/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.4642 - accuracy: 0.8369 - val_loss: 0.4833 - val_accuracy: 0.8390\n",
      "Epoch 9/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.4341 - accuracy: 0.8487 - val_loss: 0.4979 - val_accuracy: 0.8357\n",
      "Epoch 10/10\n",
      "391/391 [==============================] - 73s 186ms/step - loss: 0.4054 - accuracy: 0.8579 - val_loss: 0.3916 - val_accuracy: 0.8652\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.5725 - accuracy: 0.8204\n",
      "Test loss: 0.5725135803222656\n",
      "Test accuracy: 0.8203999996185303\n"
     ]
    }
   ],
   "source": [
    "zoom_model=modell(X_train_zoom,X_cv_zoom,X_test_zoom,y_train,y_cv,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v9nZ_06A-r2-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy without augumentation = 0.7849000096321106\n",
      "test_accuracy with shifting = 0.5189999938011169\n",
      "test_accuracy with fliping = 0.7170000076293945\n",
      "test_accuracy with brightness = 0.7968000173568726\n",
      "test_accuracy with sytandadised = 0.7972000241279602\n",
      "test_accuracy with zoom = 0.8203999996185303\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy without augumentation =\", 0.7849000096321106)\n",
    "print(\"test_accuracy with shifting =\" , 0.5189999938011169)\n",
    "print(\"test_accuracy with fliping =\" , 0.7170000076293945)\n",
    "print(\"test_accuracy with brightness =\" , 0.7968000173568726)\n",
    "print(\"test_accuracy with standadised =\", 0.7972000241279602) \n",
    "print(\"test_accuracy with zoom =\", 0.8203999996185303)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbQ8XhIZA2FY"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "- shifting perfrom worst \n",
    "- so we can include rest other fliping ,brightness,zoom, standardize\n",
    "\n",
    "\n",
    "## Hyperparameters\n",
    "- batch_size = 128\n",
    "- num_classes = 10\n",
    "- l = 8\n",
    "- num_filter = 27\n",
    "- compression =1\n",
    "- dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UjyPwMJlA1_F"
   },
   "source": [
    "**for me this configuration perform good as model also dont overfit** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4rBYROOmA122",
    "outputId": "f05776a2-81dd-44c7-d061-065ebc944227",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_23\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 32, 32, 27)   324         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 32, 32, 27)   108         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 32, 32, 27)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 32, 32, 27)   6561        activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_192 (Concatenate)   (None, 32, 32, 54)   0           conv2d_221[0][0]                 \n",
      "                                                                 conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 32, 32, 54)   216         concatenate_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 32, 32, 54)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 32, 32, 27)   13122       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_193 (Concatenate)   (None, 32, 32, 81)   0           concatenate_192[0][0]            \n",
      "                                                                 conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 32, 32, 81)   324         concatenate_193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 32, 32, 81)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 32, 32, 27)   19683       activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_194 (Concatenate)   (None, 32, 32, 108)  0           concatenate_193[0][0]            \n",
      "                                                                 conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 32, 32, 108)  432         concatenate_194[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 32, 32, 108)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 32, 32, 27)   26244       activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_195 (Concatenate)   (None, 32, 32, 135)  0           concatenate_194[0][0]            \n",
      "                                                                 conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 32, 32, 135)  540         concatenate_195[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 32, 32, 135)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 32, 32, 27)   32805       activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_196 (Concatenate)   (None, 32, 32, 162)  0           concatenate_195[0][0]            \n",
      "                                                                 conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 32, 32, 162)  648         concatenate_196[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 32, 32, 162)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 32, 32, 27)   39366       activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_197 (Concatenate)   (None, 32, 32, 189)  0           concatenate_196[0][0]            \n",
      "                                                                 conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 32, 32, 189)  756         concatenate_197[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 32, 32, 189)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 32, 32, 27)   45927       activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_198 (Concatenate)   (None, 32, 32, 216)  0           concatenate_197[0][0]            \n",
      "                                                                 conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 32, 32, 216)  864         concatenate_198[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 32, 32, 216)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 32, 32, 27)   52488       activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_199 (Concatenate)   (None, 32, 32, 243)  0           concatenate_198[0][0]            \n",
      "                                                                 conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 32, 32, 243)  972         concatenate_199[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 32, 32, 243)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 32, 32, 27)   6561        activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 16, 16, 27)   0           conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 16, 16, 27)   108         average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 16, 16, 27)   0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 16, 16, 27)   6561        activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_200 (Concatenate)   (None, 16, 16, 54)   0           average_pooling2d_24[0][0]       \n",
      "                                                                 conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 16, 16, 54)   216         concatenate_200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 16, 16, 54)   0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 16, 16, 27)   13122       activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_201 (Concatenate)   (None, 16, 16, 81)   0           concatenate_200[0][0]            \n",
      "                                                                 conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 16, 16, 81)   324         concatenate_201[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 16, 16, 81)   0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 16, 16, 27)   19683       activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_202 (Concatenate)   (None, 16, 16, 108)  0           concatenate_201[0][0]            \n",
      "                                                                 conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 16, 16, 108)  432         concatenate_202[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 16, 16, 108)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 16, 16, 27)   26244       activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_203 (Concatenate)   (None, 16, 16, 135)  0           concatenate_202[0][0]            \n",
      "                                                                 conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 16, 16, 135)  540         concatenate_203[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 16, 16, 135)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 16, 16, 27)   32805       activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_204 (Concatenate)   (None, 16, 16, 162)  0           concatenate_203[0][0]            \n",
      "                                                                 conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 16, 16, 162)  648         concatenate_204[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 16, 16, 162)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 16, 16, 27)   39366       activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_205 (Concatenate)   (None, 16, 16, 189)  0           concatenate_204[0][0]            \n",
      "                                                                 conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 16, 16, 189)  756         concatenate_205[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 16, 16, 189)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 16, 16, 27)   45927       activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_206 (Concatenate)   (None, 16, 16, 216)  0           concatenate_205[0][0]            \n",
      "                                                                 conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 16, 16, 216)  864         concatenate_206[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 16, 16, 216)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 16, 16, 27)   52488       activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_207 (Concatenate)   (None, 16, 16, 243)  0           concatenate_206[0][0]            \n",
      "                                                                 conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 16, 16, 243)  972         concatenate_207[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 16, 16, 243)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 16, 16, 27)   6561        activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 8, 8, 27)     0           conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 8, 8, 27)     108         average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 8, 8, 27)     0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 8, 8, 27)     6561        activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_208 (Concatenate)   (None, 8, 8, 54)     0           average_pooling2d_25[0][0]       \n",
      "                                                                 conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 8, 8, 54)     216         concatenate_208[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 8, 8, 54)     0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 8, 8, 27)     13122       activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_209 (Concatenate)   (None, 8, 8, 81)     0           concatenate_208[0][0]            \n",
      "                                                                 conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 8, 8, 81)     324         concatenate_209[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 8, 8, 81)     0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 8, 8, 27)     19683       activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_210 (Concatenate)   (None, 8, 8, 108)    0           concatenate_209[0][0]            \n",
      "                                                                 conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 8, 8, 108)    432         concatenate_210[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 8, 8, 108)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 8, 8, 27)     26244       activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_211 (Concatenate)   (None, 8, 8, 135)    0           concatenate_210[0][0]            \n",
      "                                                                 conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 8, 8, 135)    540         concatenate_211[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 8, 8, 135)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 8, 8, 27)     32805       activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_212 (Concatenate)   (None, 8, 8, 162)    0           concatenate_211[0][0]            \n",
      "                                                                 conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 8, 8, 162)    648         concatenate_212[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 8, 8, 162)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 8, 8, 27)     39366       activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_213 (Concatenate)   (None, 8, 8, 189)    0           concatenate_212[0][0]            \n",
      "                                                                 conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 8, 8, 189)    756         concatenate_213[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 8, 8, 189)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 8, 8, 27)     45927       activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_214 (Concatenate)   (None, 8, 8, 216)    0           concatenate_213[0][0]            \n",
      "                                                                 conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 8, 8, 216)    864         concatenate_214[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 8, 8, 216)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 8, 8, 27)     52488       activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_215 (Concatenate)   (None, 8, 8, 243)    0           concatenate_214[0][0]            \n",
      "                                                                 conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 8, 8, 243)    972         concatenate_215[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 8, 8, 243)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 8, 8, 27)     6561        activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 4, 4, 27)     0           conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 4, 4, 27)     108         average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 4, 4, 27)     0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 4, 4, 27)     6561        activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_216 (Concatenate)   (None, 4, 4, 54)     0           average_pooling2d_26[0][0]       \n",
      "                                                                 conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 4, 4, 54)     216         concatenate_216[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 4, 4, 54)     0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 4, 4, 27)     13122       activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_217 (Concatenate)   (None, 4, 4, 81)     0           concatenate_216[0][0]            \n",
      "                                                                 conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 4, 4, 81)     324         concatenate_217[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 4, 4, 81)     0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 4, 4, 27)     19683       activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_218 (Concatenate)   (None, 4, 4, 108)    0           concatenate_217[0][0]            \n",
      "                                                                 conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 4, 4, 108)    432         concatenate_218[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 4, 4, 108)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 4, 4, 27)     26244       activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_219 (Concatenate)   (None, 4, 4, 135)    0           concatenate_218[0][0]            \n",
      "                                                                 conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 4, 4, 135)    540         concatenate_219[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 4, 4, 135)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 4, 4, 27)     32805       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_220 (Concatenate)   (None, 4, 4, 162)    0           concatenate_219[0][0]            \n",
      "                                                                 conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 4, 4, 162)    648         concatenate_220[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 4, 4, 162)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 4, 4, 27)     39366       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_221 (Concatenate)   (None, 4, 4, 189)    0           concatenate_220[0][0]            \n",
      "                                                                 conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 4, 4, 189)    756         concatenate_221[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 4, 4, 189)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 4, 4, 27)     45927       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_222 (Concatenate)   (None, 4, 4, 216)    0           concatenate_221[0][0]            \n",
      "                                                                 conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 4, 4, 216)    864         concatenate_222[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 4, 4, 216)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 4, 4, 27)     52488       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_223 (Concatenate)   (None, 4, 4, 243)    0           concatenate_222[0][0]            \n",
      "                                                                 conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 4, 4, 243)    972         concatenate_223[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 4, 4, 243)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 2, 2, 243)    0           activation_251[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_11 (Flatten)            (None, 972)          0           average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 10)           9730        flatten_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "*************************************after removing last dense layer******************************************\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "Model: \"functional_25\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 32, 32, 27)   324         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 32, 32, 27)   108         conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 32, 32, 27)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 32, 32, 27)   6561        activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_192 (Concatenate)   (None, 32, 32, 54)   0           conv2d_221[0][0]                 \n",
      "                                                                 conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 32, 32, 54)   216         concatenate_192[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 32, 32, 54)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 32, 32, 27)   13122       activation_217[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_193 (Concatenate)   (None, 32, 32, 81)   0           concatenate_192[0][0]            \n",
      "                                                                 conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 32, 32, 81)   324         concatenate_193[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 32, 32, 81)   0           batch_normalization_218[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 32, 32, 27)   19683       activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_194 (Concatenate)   (None, 32, 32, 108)  0           concatenate_193[0][0]            \n",
      "                                                                 conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 32, 32, 108)  432         concatenate_194[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 32, 32, 108)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 32, 32, 27)   26244       activation_219[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_195 (Concatenate)   (None, 32, 32, 135)  0           concatenate_194[0][0]            \n",
      "                                                                 conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 32, 32, 135)  540         concatenate_195[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 32, 32, 135)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 32, 32, 27)   32805       activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_196 (Concatenate)   (None, 32, 32, 162)  0           concatenate_195[0][0]            \n",
      "                                                                 conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 32, 32, 162)  648         concatenate_196[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 32, 32, 162)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 32, 32, 27)   39366       activation_221[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_197 (Concatenate)   (None, 32, 32, 189)  0           concatenate_196[0][0]            \n",
      "                                                                 conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 32, 32, 189)  756         concatenate_197[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 32, 32, 189)  0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 32, 32, 27)   45927       activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_198 (Concatenate)   (None, 32, 32, 216)  0           concatenate_197[0][0]            \n",
      "                                                                 conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 32, 32, 216)  864         concatenate_198[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 32, 32, 216)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_229 (Conv2D)             (None, 32, 32, 27)   52488       activation_223[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_199 (Concatenate)   (None, 32, 32, 243)  0           concatenate_198[0][0]            \n",
      "                                                                 conv2d_229[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 32, 32, 243)  972         concatenate_199[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 32, 32, 243)  0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_230 (Conv2D)             (None, 32, 32, 27)   6561        activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_24 (AveragePo (None, 16, 16, 27)   0           conv2d_230[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 16, 16, 27)   108         average_pooling2d_24[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_225 (Activation)     (None, 16, 16, 27)   0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_231 (Conv2D)             (None, 16, 16, 27)   6561        activation_225[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_200 (Concatenate)   (None, 16, 16, 54)   0           average_pooling2d_24[0][0]       \n",
      "                                                                 conv2d_231[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 16, 16, 54)   216         concatenate_200[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_226 (Activation)     (None, 16, 16, 54)   0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_232 (Conv2D)             (None, 16, 16, 27)   13122       activation_226[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_201 (Concatenate)   (None, 16, 16, 81)   0           concatenate_200[0][0]            \n",
      "                                                                 conv2d_232[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 16, 16, 81)   324         concatenate_201[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_227 (Activation)     (None, 16, 16, 81)   0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_233 (Conv2D)             (None, 16, 16, 27)   19683       activation_227[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_202 (Concatenate)   (None, 16, 16, 108)  0           concatenate_201[0][0]            \n",
      "                                                                 conv2d_233[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 16, 16, 108)  432         concatenate_202[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_228 (Activation)     (None, 16, 16, 108)  0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_234 (Conv2D)             (None, 16, 16, 27)   26244       activation_228[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_203 (Concatenate)   (None, 16, 16, 135)  0           concatenate_202[0][0]            \n",
      "                                                                 conv2d_234[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 16, 16, 135)  540         concatenate_203[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_229 (Activation)     (None, 16, 16, 135)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_235 (Conv2D)             (None, 16, 16, 27)   32805       activation_229[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_204 (Concatenate)   (None, 16, 16, 162)  0           concatenate_203[0][0]            \n",
      "                                                                 conv2d_235[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 16, 16, 162)  648         concatenate_204[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_230 (Activation)     (None, 16, 16, 162)  0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_236 (Conv2D)             (None, 16, 16, 27)   39366       activation_230[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_205 (Concatenate)   (None, 16, 16, 189)  0           concatenate_204[0][0]            \n",
      "                                                                 conv2d_236[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 16, 16, 189)  756         concatenate_205[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_231 (Activation)     (None, 16, 16, 189)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_237 (Conv2D)             (None, 16, 16, 27)   45927       activation_231[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_206 (Concatenate)   (None, 16, 16, 216)  0           concatenate_205[0][0]            \n",
      "                                                                 conv2d_237[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 16, 16, 216)  864         concatenate_206[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_232 (Activation)     (None, 16, 16, 216)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_238 (Conv2D)             (None, 16, 16, 27)   52488       activation_232[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_207 (Concatenate)   (None, 16, 16, 243)  0           concatenate_206[0][0]            \n",
      "                                                                 conv2d_238[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 16, 16, 243)  972         concatenate_207[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_233 (Activation)     (None, 16, 16, 243)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_239 (Conv2D)             (None, 16, 16, 27)   6561        activation_233[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_25 (AveragePo (None, 8, 8, 27)     0           conv2d_239[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 8, 8, 27)     108         average_pooling2d_25[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_234 (Activation)     (None, 8, 8, 27)     0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_240 (Conv2D)             (None, 8, 8, 27)     6561        activation_234[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_208 (Concatenate)   (None, 8, 8, 54)     0           average_pooling2d_25[0][0]       \n",
      "                                                                 conv2d_240[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 8, 8, 54)     216         concatenate_208[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_235 (Activation)     (None, 8, 8, 54)     0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_241 (Conv2D)             (None, 8, 8, 27)     13122       activation_235[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_209 (Concatenate)   (None, 8, 8, 81)     0           concatenate_208[0][0]            \n",
      "                                                                 conv2d_241[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 8, 8, 81)     324         concatenate_209[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_236 (Activation)     (None, 8, 8, 81)     0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_242 (Conv2D)             (None, 8, 8, 27)     19683       activation_236[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_210 (Concatenate)   (None, 8, 8, 108)    0           concatenate_209[0][0]            \n",
      "                                                                 conv2d_242[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 8, 8, 108)    432         concatenate_210[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_237 (Activation)     (None, 8, 8, 108)    0           batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_243 (Conv2D)             (None, 8, 8, 27)     26244       activation_237[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_211 (Concatenate)   (None, 8, 8, 135)    0           concatenate_210[0][0]            \n",
      "                                                                 conv2d_243[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 8, 8, 135)    540         concatenate_211[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_238 (Activation)     (None, 8, 8, 135)    0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_244 (Conv2D)             (None, 8, 8, 27)     32805       activation_238[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_212 (Concatenate)   (None, 8, 8, 162)    0           concatenate_211[0][0]            \n",
      "                                                                 conv2d_244[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 8, 8, 162)    648         concatenate_212[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_239 (Activation)     (None, 8, 8, 162)    0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_245 (Conv2D)             (None, 8, 8, 27)     39366       activation_239[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_213 (Concatenate)   (None, 8, 8, 189)    0           concatenate_212[0][0]            \n",
      "                                                                 conv2d_245[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 8, 8, 189)    756         concatenate_213[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_240 (Activation)     (None, 8, 8, 189)    0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_246 (Conv2D)             (None, 8, 8, 27)     45927       activation_240[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_214 (Concatenate)   (None, 8, 8, 216)    0           concatenate_213[0][0]            \n",
      "                                                                 conv2d_246[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 8, 8, 216)    864         concatenate_214[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_241 (Activation)     (None, 8, 8, 216)    0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_247 (Conv2D)             (None, 8, 8, 27)     52488       activation_241[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_215 (Concatenate)   (None, 8, 8, 243)    0           concatenate_214[0][0]            \n",
      "                                                                 conv2d_247[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 8, 8, 243)    972         concatenate_215[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_242 (Activation)     (None, 8, 8, 243)    0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_248 (Conv2D)             (None, 8, 8, 27)     6561        activation_242[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_26 (AveragePo (None, 4, 4, 27)     0           conv2d_248[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 4, 4, 27)     108         average_pooling2d_26[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_243 (Activation)     (None, 4, 4, 27)     0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_249 (Conv2D)             (None, 4, 4, 27)     6561        activation_243[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_216 (Concatenate)   (None, 4, 4, 54)     0           average_pooling2d_26[0][0]       \n",
      "                                                                 conv2d_249[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 4, 4, 54)     216         concatenate_216[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_244 (Activation)     (None, 4, 4, 54)     0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_250 (Conv2D)             (None, 4, 4, 27)     13122       activation_244[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_217 (Concatenate)   (None, 4, 4, 81)     0           concatenate_216[0][0]            \n",
      "                                                                 conv2d_250[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 4, 4, 81)     324         concatenate_217[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_245 (Activation)     (None, 4, 4, 81)     0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_251 (Conv2D)             (None, 4, 4, 27)     19683       activation_245[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_218 (Concatenate)   (None, 4, 4, 108)    0           concatenate_217[0][0]            \n",
      "                                                                 conv2d_251[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 4, 4, 108)    432         concatenate_218[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_246 (Activation)     (None, 4, 4, 108)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_252 (Conv2D)             (None, 4, 4, 27)     26244       activation_246[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_219 (Concatenate)   (None, 4, 4, 135)    0           concatenate_218[0][0]            \n",
      "                                                                 conv2d_252[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 4, 4, 135)    540         concatenate_219[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_247 (Activation)     (None, 4, 4, 135)    0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_253 (Conv2D)             (None, 4, 4, 27)     32805       activation_247[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_220 (Concatenate)   (None, 4, 4, 162)    0           concatenate_219[0][0]            \n",
      "                                                                 conv2d_253[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 4, 4, 162)    648         concatenate_220[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_248 (Activation)     (None, 4, 4, 162)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_254 (Conv2D)             (None, 4, 4, 27)     39366       activation_248[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_221 (Concatenate)   (None, 4, 4, 189)    0           concatenate_220[0][0]            \n",
      "                                                                 conv2d_254[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 4, 4, 189)    756         concatenate_221[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_249 (Activation)     (None, 4, 4, 189)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_255 (Conv2D)             (None, 4, 4, 27)     45927       activation_249[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_222 (Concatenate)   (None, 4, 4, 216)    0           concatenate_221[0][0]            \n",
      "                                                                 conv2d_255[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 4, 4, 216)    864         concatenate_222[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_250 (Activation)     (None, 4, 4, 216)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_256 (Conv2D)             (None, 4, 4, 27)     52488       activation_250[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_223 (Concatenate)   (None, 4, 4, 243)    0           concatenate_222[0][0]            \n",
      "                                                                 conv2d_256[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 4, 4, 243)    972         concatenate_223[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_251 (Activation)     (None, 4, 4, 243)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 2, 2, 243)    0           activation_251[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 984,231\n",
      "Trainable params: 974,511\n",
      "Non-trainable params: 9,720\n",
      "__________________________________________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n",
      "**************************************after adding conv2d layer****************************************\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "functional_25 (Functional)   (None, 2, 2, 243)         984231    \n",
      "_________________________________________________________________\n",
      "conv2d_257 (Conv2D)          (None, 1, 1, 10)          9730      \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 993,961\n",
      "Trainable params: 984,241\n",
      "Non-trainable params: 9,720\n",
      "_________________________________________________________________\n",
      "^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*^*\n"
     ]
    }
   ],
   "source": [
    "# activate network as well as replace last dense layer with convet\n",
    "input = layers.Input(shape=(img_height, img_width, channel,))\n",
    "First_Conv2D = layers.Conv2D(num_filter, (2,2), use_bias=False ,padding='same')(input)\n",
    "\n",
    "First_Block = denseblock(First_Conv2D, num_filter, dropout_rate)\n",
    "First_Transition = transition(First_Block, num_filter, dropout_rate)\n",
    "\n",
    "Second_Block = denseblock(First_Transition, num_filter, dropout_rate)\n",
    "Second_Transition = transition(Second_Block, num_filter, dropout_rate)\n",
    "\n",
    "Third_Block = denseblock(Second_Transition, num_filter, dropout_rate)\n",
    "Third_Transition = transition(Third_Block, num_filter, dropout_rate)\n",
    "\n",
    "Last_Block = denseblock(Third_Transition,  num_filter, dropout_rate)\n",
    "output = output_layer(Last_Block)\n",
    "\n",
    "base_model = Model(inputs=[input], outputs=[output])\n",
    "base_model.summary()\n",
    "print(\"^*\"*100)\n",
    "print(\"*************************************after removing last dense layer******************************************\")\n",
    "print(\"^*\"*100)\n",
    "base_model.layers.pop()\n",
    "model2 = Model(base_model.input, base_model.layers[-3].output)\n",
    "model2.summary()\n",
    "\n",
    "print(\"^*\"*100)\n",
    "print(\"**************************************after adding conv2d layer****************************************\")\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(model2)\n",
    "model.add(layers.Conv2D(10,(2,2),strides=[1,1],padding='valid',activation='softmax'))\n",
    "model.add(layers.Flatten())\n",
    "model.summary()\n",
    "print(\"^*\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQycQP0DCIri"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    \n",
    "    \n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.2,1.0],zoom_range=[0.5,1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 128
    },
    "colab_type": "code",
    "id": "KwaPis9jGBV_",
    "outputId": "6509358d-c332-4df9-93f4-84658d4de534"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive',force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JkSICpNAHue2"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint,LearningRateScheduler,CSVLogger, Callback,ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Kx50CvsFMcF"
   },
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 5, min_lr = 0.000001)\n",
    "\n",
    "          # early_stop = EarlyStopping(monitor = \"val_loss\", patience = 10)\n",
    "\n",
    "def decay_fn(epoch, lr):\n",
    "      if epoch < 50:\n",
    "          return 0.001\n",
    "      elif epoch >= 50 and epoch < 75:\n",
    "          return 0.0001\n",
    "      else:\n",
    "          return 0.00001\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(decay_fn)\n",
    "\n",
    "csv_logger = CSVLogger('training.log')\n",
    "filepath=\"/content/drive/My Drive/MyCNN/model-{epoch:03d}-{accuracy:03f}-{val_accuracy:03f}.h5'\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True,mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IJSCxllOHP5g"
   },
   "outputs": [],
   "source": [
    "          model.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=Adam(),\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "9D-9mkPbH9ko",
    "outputId": "2220404e-6596-42ed-f71b-85a070ba7ff9",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-58-4dc71d79aaa8>:6: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/390 [==============================] - ETA: 0s - loss: 1.7734 - accuracy: 0.3477\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.37620, saving model to /content/drive/My Drive/MyCNN/model-001-0.347740-0.376200.h5'\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-001-0.347740-0.376200.h5'/assets\n",
      "391/390 [==============================] - 82s 211ms/step - loss: 1.7734 - accuracy: 0.3477 - val_loss: 1.7534 - val_accuracy: 0.3762\n",
      "Epoch 2/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.3891 - accuracy: 0.5017\n",
      "Epoch 00002: val_accuracy improved from 0.37620 to 0.47610, saving model to /content/drive/My Drive/MyCNN/model-002-0.501660-0.476100.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-002-0.501660-0.476100.h5'/assets\n",
      "391/390 [==============================] - 83s 212ms/step - loss: 1.3891 - accuracy: 0.5017 - val_loss: 1.4594 - val_accuracy: 0.4761\n",
      "Epoch 3/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.1631 - accuracy: 0.5854\n",
      "Epoch 00003: val_accuracy improved from 0.47610 to 0.54510, saving model to /content/drive/My Drive/MyCNN/model-003-0.585420-0.545100.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-003-0.585420-0.545100.h5'/assets\n",
      "391/390 [==============================] - 84s 214ms/step - loss: 1.1631 - accuracy: 0.5854 - val_loss: 1.3585 - val_accuracy: 0.5451\n",
      "Epoch 4/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 1.0245 - accuracy: 0.6352\n",
      "Epoch 00004: val_accuracy improved from 0.54510 to 0.58050, saving model to /content/drive/My Drive/MyCNN/model-004-0.635240-0.580500.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-004-0.635240-0.580500.h5'/assets\n",
      "391/390 [==============================] - 84s 214ms/step - loss: 1.0245 - accuracy: 0.6352 - val_loss: 1.2581 - val_accuracy: 0.5805\n",
      "Epoch 5/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.9485 - accuracy: 0.6635\n",
      "Epoch 00005: val_accuracy improved from 0.58050 to 0.59320, saving model to /content/drive/My Drive/MyCNN/model-005-0.663540-0.593200.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-005-0.663540-0.593200.h5'/assets\n",
      "391/390 [==============================] - 84s 215ms/step - loss: 0.9485 - accuracy: 0.6635 - val_loss: 1.2857 - val_accuracy: 0.5932\n",
      "Epoch 6/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8854 - accuracy: 0.6864\n",
      "Epoch 00006: val_accuracy improved from 0.59320 to 0.66820, saving model to /content/drive/My Drive/MyCNN/model-006-0.686420-0.668200.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-006-0.686420-0.668200.h5'/assets\n",
      "391/390 [==============================] - 84s 215ms/step - loss: 0.8854 - accuracy: 0.6864 - val_loss: 0.9889 - val_accuracy: 0.6682\n",
      "Epoch 7/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.8398 - accuracy: 0.7035\n",
      "Epoch 00007: val_accuracy did not improve from 0.66820\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.8398 - accuracy: 0.7035 - val_loss: 1.1797 - val_accuracy: 0.6053\n",
      "Epoch 8/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7958 - accuracy: 0.7195\n",
      "Epoch 00008: val_accuracy improved from 0.66820 to 0.69180, saving model to /content/drive/My Drive/MyCNN/model-008-0.719500-0.691800.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-008-0.719500-0.691800.h5'/assets\n",
      "391/390 [==============================] - 85s 217ms/step - loss: 0.7958 - accuracy: 0.7195 - val_loss: 0.8805 - val_accuracy: 0.6918\n",
      "Epoch 9/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7551 - accuracy: 0.7341\n",
      "Epoch 00009: val_accuracy did not improve from 0.69180\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.7551 - accuracy: 0.7341 - val_loss: 1.0625 - val_accuracy: 0.6509\n",
      "Epoch 10/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7378 - accuracy: 0.7390\n",
      "Epoch 00010: val_accuracy did not improve from 0.69180\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.7378 - accuracy: 0.7390 - val_loss: 1.0165 - val_accuracy: 0.6730\n",
      "Epoch 11/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.7025 - accuracy: 0.7509\n",
      "Epoch 00011: val_accuracy improved from 0.69180 to 0.72910, saving model to /content/drive/My Drive/MyCNN/model-011-0.750940-0.729100.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-011-0.750940-0.729100.h5'/assets\n",
      "391/390 [==============================] - 85s 218ms/step - loss: 0.7025 - accuracy: 0.7509 - val_loss: 0.7849 - val_accuracy: 0.7291\n",
      "Epoch 12/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6807 - accuracy: 0.7607\n",
      "Epoch 00012: val_accuracy improved from 0.72910 to 0.75750, saving model to /content/drive/My Drive/MyCNN/model-012-0.760740-0.757500.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-012-0.760740-0.757500.h5'/assets\n",
      "391/390 [==============================] - 85s 218ms/step - loss: 0.6807 - accuracy: 0.7607 - val_loss: 0.7010 - val_accuracy: 0.7575\n",
      "Epoch 13/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6642 - accuracy: 0.7667\n",
      "Epoch 00013: val_accuracy did not improve from 0.75750\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.6642 - accuracy: 0.7667 - val_loss: 0.7981 - val_accuracy: 0.7361\n",
      "Epoch 14/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6443 - accuracy: 0.7749\n",
      "Epoch 00014: val_accuracy did not improve from 0.75750\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.6443 - accuracy: 0.7749 - val_loss: 0.7591 - val_accuracy: 0.7357\n",
      "Epoch 15/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6220 - accuracy: 0.7820\n",
      "Epoch 00015: val_accuracy did not improve from 0.75750\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.6220 - accuracy: 0.7820 - val_loss: 0.8640 - val_accuracy: 0.7095\n",
      "Epoch 16/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.6111 - accuracy: 0.7853\n",
      "Epoch 00016: val_accuracy did not improve from 0.75750\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.6111 - accuracy: 0.7853 - val_loss: 0.7388 - val_accuracy: 0.7489\n",
      "Epoch 17/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5929 - accuracy: 0.7904\n",
      "Epoch 00017: val_accuracy did not improve from 0.75750\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.5929 - accuracy: 0.7904 - val_loss: 0.7299 - val_accuracy: 0.7546\n",
      "Epoch 18/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5740 - accuracy: 0.7976\n",
      "Epoch 00018: val_accuracy improved from 0.75750 to 0.77200, saving model to /content/drive/My Drive/MyCNN/model-018-0.797600-0.772000.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-018-0.797600-0.772000.h5'/assets\n",
      "391/390 [==============================] - 85s 218ms/step - loss: 0.5740 - accuracy: 0.7976 - val_loss: 0.6865 - val_accuracy: 0.7720\n",
      "Epoch 19/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5602 - accuracy: 0.8033\n",
      "Epoch 00019: val_accuracy did not improve from 0.77200\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.5602 - accuracy: 0.8033 - val_loss: 0.7116 - val_accuracy: 0.7571\n",
      "Epoch 20/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5509 - accuracy: 0.8075\n",
      "Epoch 00020: val_accuracy did not improve from 0.77200\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.5509 - accuracy: 0.8075 - val_loss: 0.7239 - val_accuracy: 0.7519\n",
      "Epoch 21/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5361 - accuracy: 0.8127\n",
      "Epoch 00021: val_accuracy did not improve from 0.77200\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.5361 - accuracy: 0.8127 - val_loss: 0.6994 - val_accuracy: 0.7683\n",
      "Epoch 22/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5247 - accuracy: 0.8155\n",
      "Epoch 00022: val_accuracy did not improve from 0.77200\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.5247 - accuracy: 0.8155 - val_loss: 0.7839 - val_accuracy: 0.7408\n",
      "Epoch 23/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.8179\n",
      "Epoch 00023: val_accuracy improved from 0.77200 to 0.80800, saving model to /content/drive/My Drive/MyCNN/model-023-0.817940-0.808000.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-023-0.817940-0.808000.h5'/assets\n",
      "391/390 [==============================] - 85s 217ms/step - loss: 0.5138 - accuracy: 0.8179 - val_loss: 0.5617 - val_accuracy: 0.8080\n",
      "Epoch 24/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.8232\n",
      "Epoch 00024: val_accuracy did not improve from 0.80800\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.5040 - accuracy: 0.8232 - val_loss: 0.8523 - val_accuracy: 0.7206\n",
      "Epoch 25/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4947 - accuracy: 0.8288\n",
      "Epoch 00025: val_accuracy did not improve from 0.80800\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.4947 - accuracy: 0.8288 - val_loss: 0.5764 - val_accuracy: 0.7995\n",
      "Epoch 26/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4891 - accuracy: 0.8277\n",
      "Epoch 00026: val_accuracy did not improve from 0.80800\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.4891 - accuracy: 0.8277 - val_loss: 0.6192 - val_accuracy: 0.7827\n",
      "Epoch 27/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4729 - accuracy: 0.8339\n",
      "Epoch 00027: val_accuracy did not improve from 0.80800\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.4729 - accuracy: 0.8339 - val_loss: 0.6097 - val_accuracy: 0.7892\n",
      "Epoch 28/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4708 - accuracy: 0.8346\n",
      "Epoch 00028: val_accuracy did not improve from 0.80800\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.4708 - accuracy: 0.8346 - val_loss: 0.7420 - val_accuracy: 0.7609\n",
      "Epoch 29/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4594 - accuracy: 0.8381\n",
      "Epoch 00029: val_accuracy did not improve from 0.80800\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.4594 - accuracy: 0.8381 - val_loss: 0.5913 - val_accuracy: 0.8011\n",
      "Epoch 30/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4533 - accuracy: 0.8404\n",
      "Epoch 00030: val_accuracy did not improve from 0.80800\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.4533 - accuracy: 0.8404 - val_loss: 0.6015 - val_accuracy: 0.7982\n",
      "Epoch 31/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4449 - accuracy: 0.8446\n",
      "Epoch 00031: val_accuracy did not improve from 0.80800\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.4449 - accuracy: 0.8446 - val_loss: 0.6799 - val_accuracy: 0.7764\n",
      "Epoch 32/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4380 - accuracy: 0.8461\n",
      "Epoch 00032: val_accuracy did not improve from 0.80800\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.4380 - accuracy: 0.8461 - val_loss: 0.5862 - val_accuracy: 0.8024\n",
      "Epoch 33/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4342 - accuracy: 0.8461\n",
      "Epoch 00033: val_accuracy improved from 0.80800 to 0.81470, saving model to /content/drive/My Drive/MyCNN/model-033-0.846060-0.814700.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-033-0.846060-0.814700.h5'/assets\n",
      "391/390 [==============================] - 85s 218ms/step - loss: 0.4342 - accuracy: 0.8461 - val_loss: 0.5473 - val_accuracy: 0.8147\n",
      "Epoch 34/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4269 - accuracy: 0.8499\n",
      "Epoch 00034: val_accuracy did not improve from 0.81470\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.4269 - accuracy: 0.8499 - val_loss: 0.6605 - val_accuracy: 0.7911\n",
      "Epoch 35/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4181 - accuracy: 0.8549\n",
      "Epoch 00035: val_accuracy improved from 0.81470 to 0.82450, saving model to /content/drive/My Drive/MyCNN/model-035-0.854920-0.824500.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-035-0.854920-0.824500.h5'/assets\n",
      "391/390 [==============================] - 84s 216ms/step - loss: 0.4181 - accuracy: 0.8549 - val_loss: 0.5045 - val_accuracy: 0.8245\n",
      "Epoch 36/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4094 - accuracy: 0.8553\n",
      "Epoch 00036: val_accuracy did not improve from 0.82450\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.4094 - accuracy: 0.8553 - val_loss: 0.7371 - val_accuracy: 0.7552\n",
      "Epoch 37/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4079 - accuracy: 0.8570\n",
      "Epoch 00037: val_accuracy improved from 0.82450 to 0.83650, saving model to /content/drive/My Drive/MyCNN/model-037-0.856960-0.836500.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-037-0.856960-0.836500.h5'/assets\n",
      "391/390 [==============================] - 85s 217ms/step - loss: 0.4079 - accuracy: 0.8570 - val_loss: 0.4986 - val_accuracy: 0.8365\n",
      "Epoch 38/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.4057 - accuracy: 0.8561\n",
      "Epoch 00038: val_accuracy did not improve from 0.83650\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.4057 - accuracy: 0.8561 - val_loss: 0.4896 - val_accuracy: 0.8312\n",
      "Epoch 39/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3970 - accuracy: 0.8603\n",
      "Epoch 00039: val_accuracy did not improve from 0.83650\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.3970 - accuracy: 0.8603 - val_loss: 0.5746 - val_accuracy: 0.8074\n",
      "Epoch 40/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3920 - accuracy: 0.8621\n",
      "Epoch 00040: val_accuracy did not improve from 0.83650\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.3920 - accuracy: 0.8621 - val_loss: 0.8043 - val_accuracy: 0.7640\n",
      "Epoch 41/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3794 - accuracy: 0.8683\n",
      "Epoch 00041: val_accuracy improved from 0.83650 to 0.84600, saving model to /content/drive/My Drive/MyCNN/model-041-0.868340-0.846000.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-041-0.868340-0.846000.h5'/assets\n",
      "391/390 [==============================] - 85s 217ms/step - loss: 0.3794 - accuracy: 0.8683 - val_loss: 0.4603 - val_accuracy: 0.8460\n",
      "Epoch 42/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3764 - accuracy: 0.8664\n",
      "Epoch 00042: val_accuracy did not improve from 0.84600\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.3764 - accuracy: 0.8664 - val_loss: 0.6478 - val_accuracy: 0.7944\n",
      "Epoch 43/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3704 - accuracy: 0.8692\n",
      "Epoch 00043: val_accuracy did not improve from 0.84600\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.3704 - accuracy: 0.8692 - val_loss: 0.4941 - val_accuracy: 0.8326\n",
      "Epoch 44/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3716 - accuracy: 0.8685\n",
      "Epoch 00044: val_accuracy did not improve from 0.84600\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.3716 - accuracy: 0.8685 - val_loss: 0.5154 - val_accuracy: 0.8244\n",
      "Epoch 45/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3656 - accuracy: 0.8716\n",
      "Epoch 00045: val_accuracy improved from 0.84600 to 0.86250, saving model to /content/drive/My Drive/MyCNN/model-045-0.871620-0.862500.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-045-0.871620-0.862500.h5'/assets\n",
      "391/390 [==============================] - 85s 218ms/step - loss: 0.3656 - accuracy: 0.8716 - val_loss: 0.4139 - val_accuracy: 0.8625\n",
      "Epoch 46/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3586 - accuracy: 0.8736\n",
      "Epoch 00046: val_accuracy did not improve from 0.86250\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.3586 - accuracy: 0.8736 - val_loss: 0.5008 - val_accuracy: 0.8325\n",
      "Epoch 47/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3572 - accuracy: 0.8737\n",
      "Epoch 00047: val_accuracy did not improve from 0.86250\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.3572 - accuracy: 0.8737 - val_loss: 0.4338 - val_accuracy: 0.8549\n",
      "Epoch 48/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3490 - accuracy: 0.8776\n",
      "Epoch 00048: val_accuracy did not improve from 0.86250\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.3490 - accuracy: 0.8776 - val_loss: 0.4239 - val_accuracy: 0.8547\n",
      "Epoch 49/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3484 - accuracy: 0.8800\n",
      "Epoch 00049: val_accuracy did not improve from 0.86250\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.3484 - accuracy: 0.8800 - val_loss: 0.4427 - val_accuracy: 0.8445\n",
      "Epoch 50/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3486 - accuracy: 0.8770\n",
      "Epoch 00050: val_accuracy did not improve from 0.86250\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.3486 - accuracy: 0.8770 - val_loss: 0.4254 - val_accuracy: 0.8524\n",
      "Epoch 51/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.8800\n",
      "Epoch 00051: val_accuracy did not improve from 0.86250\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.3382 - accuracy: 0.8800 - val_loss: 0.4381 - val_accuracy: 0.8498\n",
      "Epoch 52/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.8807\n",
      "Epoch 00052: val_accuracy did not improve from 0.86250\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.3395 - accuracy: 0.8807 - val_loss: 0.4811 - val_accuracy: 0.8419\n",
      "Epoch 53/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3336 - accuracy: 0.8812\n",
      "Epoch 00053: val_accuracy did not improve from 0.86250\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.3336 - accuracy: 0.8812 - val_loss: 0.3974 - val_accuracy: 0.8620\n",
      "Epoch 54/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3282 - accuracy: 0.8862\n",
      "Epoch 00054: val_accuracy improved from 0.86250 to 0.86260, saving model to /content/drive/My Drive/MyCNN/model-054-0.886160-0.862600.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-054-0.886160-0.862600.h5'/assets\n",
      "391/390 [==============================] - 85s 217ms/step - loss: 0.3282 - accuracy: 0.8862 - val_loss: 0.4030 - val_accuracy: 0.8626\n",
      "Epoch 55/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3271 - accuracy: 0.8844\n",
      "Epoch 00055: val_accuracy did not improve from 0.86260\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.3271 - accuracy: 0.8844 - val_loss: 0.4242 - val_accuracy: 0.8538\n",
      "Epoch 56/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3138 - accuracy: 0.8889\n",
      "Epoch 00056: val_accuracy did not improve from 0.86260\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.3138 - accuracy: 0.8889 - val_loss: 0.4589 - val_accuracy: 0.8440\n",
      "Epoch 57/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3198 - accuracy: 0.8874\n",
      "Epoch 00057: val_accuracy improved from 0.86260 to 0.86630, saving model to /content/drive/My Drive/MyCNN/model-057-0.887400-0.866300.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-057-0.887400-0.866300.h5'/assets\n",
      "391/390 [==============================] - 85s 218ms/step - loss: 0.3198 - accuracy: 0.8874 - val_loss: 0.3822 - val_accuracy: 0.8663\n",
      "Epoch 58/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3116 - accuracy: 0.8891\n",
      "Epoch 00058: val_accuracy did not improve from 0.86630\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.3116 - accuracy: 0.8891 - val_loss: 0.4669 - val_accuracy: 0.8457\n",
      "Epoch 59/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3125 - accuracy: 0.8901\n",
      "Epoch 00059: val_accuracy did not improve from 0.86630\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.3125 - accuracy: 0.8901 - val_loss: 0.4402 - val_accuracy: 0.8489\n",
      "Epoch 60/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3139 - accuracy: 0.8904\n",
      "Epoch 00060: val_accuracy improved from 0.86630 to 0.86830, saving model to /content/drive/My Drive/MyCNN/model-060-0.890420-0.868300.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-060-0.890420-0.868300.h5'/assets\n",
      "391/390 [==============================] - 84s 216ms/step - loss: 0.3139 - accuracy: 0.8904 - val_loss: 0.3915 - val_accuracy: 0.8683\n",
      "Epoch 61/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3034 - accuracy: 0.8934\n",
      "Epoch 00061: val_accuracy did not improve from 0.86830\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.3034 - accuracy: 0.8934 - val_loss: 0.5545 - val_accuracy: 0.8254\n",
      "Epoch 62/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.8942\n",
      "Epoch 00062: val_accuracy did not improve from 0.86830\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.3007 - accuracy: 0.8942 - val_loss: 0.4904 - val_accuracy: 0.8425\n",
      "Epoch 63/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.3007 - accuracy: 0.8950\n",
      "Epoch 00063: val_accuracy improved from 0.86830 to 0.87760, saving model to /content/drive/My Drive/MyCNN/model-063-0.894980-0.877600.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-063-0.894980-0.877600.h5'/assets\n",
      "391/390 [==============================] - 85s 218ms/step - loss: 0.3007 - accuracy: 0.8950 - val_loss: 0.3597 - val_accuracy: 0.8776\n",
      "Epoch 64/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2947 - accuracy: 0.8950\n",
      "Epoch 00064: val_accuracy improved from 0.87760 to 0.89160, saving model to /content/drive/My Drive/MyCNN/model-064-0.895000-0.891600.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-064-0.895000-0.891600.h5'/assets\n",
      "391/390 [==============================] - 85s 217ms/step - loss: 0.2947 - accuracy: 0.8950 - val_loss: 0.3220 - val_accuracy: 0.8916\n",
      "Epoch 65/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2976 - accuracy: 0.8964\n",
      "Epoch 00065: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.2976 - accuracy: 0.8964 - val_loss: 0.4008 - val_accuracy: 0.8661\n",
      "Epoch 66/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2898 - accuracy: 0.8976\n",
      "Epoch 00066: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2898 - accuracy: 0.8976 - val_loss: 0.3605 - val_accuracy: 0.8733\n",
      "Epoch 67/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.8992\n",
      "Epoch 00067: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2861 - accuracy: 0.8992 - val_loss: 0.3833 - val_accuracy: 0.8706\n",
      "Epoch 68/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2830 - accuracy: 0.9009\n",
      "Epoch 00068: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2830 - accuracy: 0.9009 - val_loss: 0.4644 - val_accuracy: 0.8485\n",
      "Epoch 69/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.9008\n",
      "Epoch 00069: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2855 - accuracy: 0.9008 - val_loss: 0.3894 - val_accuracy: 0.8704\n",
      "Epoch 70/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2816 - accuracy: 0.8990\n",
      "Epoch 00070: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2816 - accuracy: 0.8990 - val_loss: 0.3718 - val_accuracy: 0.8760\n",
      "Epoch 71/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.9027\n",
      "Epoch 00071: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2759 - accuracy: 0.9027 - val_loss: 0.3099 - val_accuracy: 0.8891\n",
      "Epoch 72/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.9041\n",
      "Epoch 00072: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2736 - accuracy: 0.9041 - val_loss: 0.3670 - val_accuracy: 0.8776\n",
      "Epoch 73/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2725 - accuracy: 0.9034\n",
      "Epoch 00073: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2725 - accuracy: 0.9034 - val_loss: 0.3426 - val_accuracy: 0.8782\n",
      "Epoch 74/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2665 - accuracy: 0.9059\n",
      "Epoch 00074: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2665 - accuracy: 0.9059 - val_loss: 0.4320 - val_accuracy: 0.8542\n",
      "Epoch 75/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2684 - accuracy: 0.9049\n",
      "Epoch 00075: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2684 - accuracy: 0.9049 - val_loss: 0.4885 - val_accuracy: 0.8374\n",
      "Epoch 76/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2687 - accuracy: 0.9044\n",
      "Epoch 00076: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2687 - accuracy: 0.9044 - val_loss: 0.3393 - val_accuracy: 0.8859\n",
      "Epoch 77/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.9084\n",
      "Epoch 00077: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2607 - accuracy: 0.9084 - val_loss: 0.3593 - val_accuracy: 0.8783\n",
      "Epoch 78/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2623 - accuracy: 0.9089\n",
      "Epoch 00078: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2623 - accuracy: 0.9089 - val_loss: 0.3391 - val_accuracy: 0.8844\n",
      "Epoch 79/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2607 - accuracy: 0.9070\n",
      "Epoch 00079: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2607 - accuracy: 0.9070 - val_loss: 0.3874 - val_accuracy: 0.8700\n",
      "Epoch 80/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2535 - accuracy: 0.9095\n",
      "Epoch 00080: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2535 - accuracy: 0.9095 - val_loss: 0.3706 - val_accuracy: 0.8748\n",
      "Epoch 81/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2493 - accuracy: 0.9124\n",
      "Epoch 00081: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2493 - accuracy: 0.9124 - val_loss: 0.3599 - val_accuracy: 0.8806\n",
      "Epoch 82/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2513 - accuracy: 0.9109\n",
      "Epoch 00082: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2513 - accuracy: 0.9109 - val_loss: 0.3505 - val_accuracy: 0.8837\n",
      "Epoch 83/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2501 - accuracy: 0.9106\n",
      "Epoch 00083: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2501 - accuracy: 0.9106 - val_loss: 0.3788 - val_accuracy: 0.8732\n",
      "Epoch 84/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2465 - accuracy: 0.9124\n",
      "Epoch 00084: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2465 - accuracy: 0.9124 - val_loss: 0.3868 - val_accuracy: 0.8775\n",
      "Epoch 85/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2445 - accuracy: 0.9128\n",
      "Epoch 00085: val_accuracy did not improve from 0.89160\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2445 - accuracy: 0.9128 - val_loss: 0.4038 - val_accuracy: 0.8686\n",
      "Epoch 86/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2447 - accuracy: 0.9134\n",
      "Epoch 00086: val_accuracy improved from 0.89160 to 0.89480, saving model to /content/drive/My Drive/MyCNN/model-086-0.913380-0.894800.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-086-0.913380-0.894800.h5'/assets\n",
      "391/390 [==============================] - 85s 217ms/step - loss: 0.2447 - accuracy: 0.9134 - val_loss: 0.3044 - val_accuracy: 0.8948\n",
      "Epoch 87/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2442 - accuracy: 0.9123\n",
      "Epoch 00087: val_accuracy improved from 0.89480 to 0.90320, saving model to /content/drive/My Drive/MyCNN/model-087-0.912320-0.903200.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-087-0.912320-0.903200.h5'/assets\n",
      "391/390 [==============================] - 84s 215ms/step - loss: 0.2442 - accuracy: 0.9123 - val_loss: 0.2758 - val_accuracy: 0.9032\n",
      "Epoch 88/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2395 - accuracy: 0.9146\n",
      "Epoch 00088: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 69s 176ms/step - loss: 0.2395 - accuracy: 0.9146 - val_loss: 0.3196 - val_accuracy: 0.8929\n",
      "Epoch 89/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2359 - accuracy: 0.9164\n",
      "Epoch 00089: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2359 - accuracy: 0.9164 - val_loss: 0.3821 - val_accuracy: 0.8773\n",
      "Epoch 90/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2347 - accuracy: 0.9176\n",
      "Epoch 00090: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2347 - accuracy: 0.9176 - val_loss: 0.3048 - val_accuracy: 0.8953\n",
      "Epoch 91/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2342 - accuracy: 0.9174\n",
      "Epoch 00091: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2342 - accuracy: 0.9174 - val_loss: 0.3261 - val_accuracy: 0.8895\n",
      "Epoch 92/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2348 - accuracy: 0.9162\n",
      "Epoch 00092: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2348 - accuracy: 0.9162 - val_loss: 0.4568 - val_accuracy: 0.8589\n",
      "Epoch 93/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2321 - accuracy: 0.9194\n",
      "Epoch 00093: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2321 - accuracy: 0.9194 - val_loss: 0.3109 - val_accuracy: 0.8955\n",
      "Epoch 94/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2293 - accuracy: 0.9189\n",
      "Epoch 00094: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.2293 - accuracy: 0.9189 - val_loss: 0.3207 - val_accuracy: 0.8900\n",
      "Epoch 95/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2264 - accuracy: 0.9183\n",
      "Epoch 00095: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2264 - accuracy: 0.9183 - val_loss: 0.3562 - val_accuracy: 0.8872\n",
      "Epoch 96/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2244 - accuracy: 0.9215\n",
      "Epoch 00096: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2244 - accuracy: 0.9215 - val_loss: 0.3337 - val_accuracy: 0.8884\n",
      "Epoch 97/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2256 - accuracy: 0.9210\n",
      "Epoch 00097: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2256 - accuracy: 0.9210 - val_loss: 0.3608 - val_accuracy: 0.8813\n",
      "Epoch 98/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2239 - accuracy: 0.9215\n",
      "Epoch 00098: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2239 - accuracy: 0.9215 - val_loss: 0.3258 - val_accuracy: 0.8904\n",
      "Epoch 99/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2145 - accuracy: 0.9230\n",
      "Epoch 00099: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2145 - accuracy: 0.9230 - val_loss: 0.3363 - val_accuracy: 0.8920\n",
      "Epoch 100/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2180 - accuracy: 0.9226\n",
      "Epoch 00100: val_accuracy did not improve from 0.90320\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.2180 - accuracy: 0.9226 - val_loss: 0.3202 - val_accuracy: 0.8963\n",
      "Epoch 101/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2162 - accuracy: 0.9226\n",
      "Epoch 00101: val_accuracy improved from 0.90320 to 0.91450, saving model to /content/drive/My Drive/MyCNN/model-101-0.922640-0.914500.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-101-0.922640-0.914500.h5'/assets\n",
      "391/390 [==============================] - 85s 217ms/step - loss: 0.2162 - accuracy: 0.9226 - val_loss: 0.2527 - val_accuracy: 0.9145\n",
      "Epoch 102/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2141 - accuracy: 0.9240\n",
      "Epoch 00102: val_accuracy did not improve from 0.91450\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.2141 - accuracy: 0.9240 - val_loss: 0.3216 - val_accuracy: 0.8925\n",
      "Epoch 103/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2140 - accuracy: 0.9247\n",
      "Epoch 00103: val_accuracy did not improve from 0.91450\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2140 - accuracy: 0.9247 - val_loss: 0.2884 - val_accuracy: 0.9011\n",
      "Epoch 104/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2135 - accuracy: 0.9261\n",
      "Epoch 00104: val_accuracy did not improve from 0.91450\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.2135 - accuracy: 0.9261 - val_loss: 0.4126 - val_accuracy: 0.8702\n",
      "Epoch 105/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2119 - accuracy: 0.9245\n",
      "Epoch 00105: val_accuracy improved from 0.91450 to 0.91670, saving model to /content/drive/My Drive/MyCNN/model-105-0.924500-0.916700.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-105-0.924500-0.916700.h5'/assets\n",
      "391/390 [==============================] - 85s 216ms/step - loss: 0.2119 - accuracy: 0.9245 - val_loss: 0.2408 - val_accuracy: 0.9167\n",
      "Epoch 106/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2062 - accuracy: 0.9263\n",
      "Epoch 00106: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.2062 - accuracy: 0.9263 - val_loss: 0.2836 - val_accuracy: 0.9041\n",
      "Epoch 107/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2090 - accuracy: 0.9267\n",
      "Epoch 00107: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.2090 - accuracy: 0.9267 - val_loss: 0.2960 - val_accuracy: 0.9009\n",
      "Epoch 108/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2056 - accuracy: 0.9271\n",
      "Epoch 00108: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2056 - accuracy: 0.9271 - val_loss: 0.3302 - val_accuracy: 0.8908\n",
      "Epoch 109/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2034 - accuracy: 0.9274\n",
      "Epoch 00109: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2034 - accuracy: 0.9274 - val_loss: 0.3411 - val_accuracy: 0.8892\n",
      "Epoch 110/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2068 - accuracy: 0.9264\n",
      "Epoch 00110: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2068 - accuracy: 0.9264 - val_loss: 0.3806 - val_accuracy: 0.8794\n",
      "Epoch 111/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1999 - accuracy: 0.9282\n",
      "Epoch 00111: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1999 - accuracy: 0.9282 - val_loss: 0.3141 - val_accuracy: 0.8992\n",
      "Epoch 112/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2032 - accuracy: 0.9283\n",
      "Epoch 00112: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2032 - accuracy: 0.9283 - val_loss: 0.2640 - val_accuracy: 0.9074\n",
      "Epoch 113/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9281\n",
      "Epoch 00113: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2017 - accuracy: 0.9281 - val_loss: 0.3242 - val_accuracy: 0.8934\n",
      "Epoch 114/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.2003 - accuracy: 0.9291\n",
      "Epoch 00114: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.2003 - accuracy: 0.9291 - val_loss: 0.3175 - val_accuracy: 0.8957\n",
      "Epoch 115/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.9292\n",
      "Epoch 00115: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1985 - accuracy: 0.9292 - val_loss: 0.3056 - val_accuracy: 0.8993\n",
      "Epoch 116/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.9310\n",
      "Epoch 00116: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1930 - accuracy: 0.9310 - val_loss: 0.3012 - val_accuracy: 0.9007\n",
      "Epoch 117/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1975 - accuracy: 0.9303\n",
      "Epoch 00117: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1975 - accuracy: 0.9303 - val_loss: 0.2920 - val_accuracy: 0.9002\n",
      "Epoch 118/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9304\n",
      "Epoch 00118: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1935 - accuracy: 0.9304 - val_loss: 0.2797 - val_accuracy: 0.9074\n",
      "Epoch 119/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1926 - accuracy: 0.9326\n",
      "Epoch 00119: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1926 - accuracy: 0.9326 - val_loss: 0.3697 - val_accuracy: 0.8802\n",
      "Epoch 120/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9332\n",
      "Epoch 00120: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.1875 - accuracy: 0.9332 - val_loss: 0.2655 - val_accuracy: 0.9096\n",
      "Epoch 121/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.9343\n",
      "Epoch 00121: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1865 - accuracy: 0.9343 - val_loss: 0.3716 - val_accuracy: 0.8866\n",
      "Epoch 122/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.9327\n",
      "Epoch 00122: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1890 - accuracy: 0.9327 - val_loss: 0.2660 - val_accuracy: 0.9088\n",
      "Epoch 123/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.9353\n",
      "Epoch 00123: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.1815 - accuracy: 0.9353 - val_loss: 0.2903 - val_accuracy: 0.9078\n",
      "Epoch 124/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1867 - accuracy: 0.9357\n",
      "Epoch 00124: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.1867 - accuracy: 0.9357 - val_loss: 0.2912 - val_accuracy: 0.9025\n",
      "Epoch 125/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9353\n",
      "Epoch 00125: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1827 - accuracy: 0.9353 - val_loss: 0.3028 - val_accuracy: 0.8949\n",
      "Epoch 126/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1847 - accuracy: 0.9341\n",
      "Epoch 00126: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 69s 177ms/step - loss: 0.1847 - accuracy: 0.9341 - val_loss: 0.3078 - val_accuracy: 0.9004\n",
      "Epoch 127/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9347\n",
      "Epoch 00127: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1830 - accuracy: 0.9347 - val_loss: 0.3517 - val_accuracy: 0.8877\n",
      "Epoch 128/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.9354\n",
      "Epoch 00128: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1786 - accuracy: 0.9354 - val_loss: 0.2638 - val_accuracy: 0.9125\n",
      "Epoch 129/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1811 - accuracy: 0.9349\n",
      "Epoch 00129: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 69s 178ms/step - loss: 0.1811 - accuracy: 0.9349 - val_loss: 0.3112 - val_accuracy: 0.9012\n",
      "Epoch 130/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1785 - accuracy: 0.9359\n",
      "Epoch 00130: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.1785 - accuracy: 0.9359 - val_loss: 0.2824 - val_accuracy: 0.9076\n",
      "Epoch 131/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1770 - accuracy: 0.9372\n",
      "Epoch 00131: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1770 - accuracy: 0.9372 - val_loss: 0.4114 - val_accuracy: 0.8744\n",
      "Epoch 132/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9376\n",
      "Epoch 00132: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1777 - accuracy: 0.9376 - val_loss: 0.3475 - val_accuracy: 0.8932\n",
      "Epoch 133/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9394\n",
      "Epoch 00133: val_accuracy did not improve from 0.91670\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1757 - accuracy: 0.9394 - val_loss: 0.2550 - val_accuracy: 0.9158\n",
      "Epoch 134/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.9368\n",
      "Epoch 00134: val_accuracy improved from 0.91670 to 0.91930, saving model to /content/drive/My Drive/MyCNN/model-134-0.936820-0.919300.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-134-0.936820-0.919300.h5'/assets\n",
      "391/390 [==============================] - 85s 218ms/step - loss: 0.1753 - accuracy: 0.9368 - val_loss: 0.2411 - val_accuracy: 0.9193\n",
      "Epoch 135/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9391\n",
      "Epoch 00135: val_accuracy did not improve from 0.91930\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.1723 - accuracy: 0.9391 - val_loss: 0.2574 - val_accuracy: 0.9147\n",
      "Epoch 136/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1768 - accuracy: 0.9361\n",
      "Epoch 00136: val_accuracy did not improve from 0.91930\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1768 - accuracy: 0.9361 - val_loss: 0.2785 - val_accuracy: 0.9098\n",
      "Epoch 137/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1724 - accuracy: 0.9380\n",
      "Epoch 00137: val_accuracy did not improve from 0.91930\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1724 - accuracy: 0.9380 - val_loss: 0.2832 - val_accuracy: 0.9080\n",
      "Epoch 138/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9401\n",
      "Epoch 00138: val_accuracy did not improve from 0.91930\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.1691 - accuracy: 0.9401 - val_loss: 0.2672 - val_accuracy: 0.9112\n",
      "Epoch 139/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9375\n",
      "Epoch 00139: val_accuracy did not improve from 0.91930\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.1769 - accuracy: 0.9375 - val_loss: 0.2952 - val_accuracy: 0.9060\n",
      "Epoch 140/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1659 - accuracy: 0.9406\n",
      "Epoch 00140: val_accuracy did not improve from 0.91930\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1659 - accuracy: 0.9406 - val_loss: 0.2970 - val_accuracy: 0.9026\n",
      "Epoch 141/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1682 - accuracy: 0.9413\n",
      "Epoch 00141: val_accuracy did not improve from 0.91930\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.1682 - accuracy: 0.9413 - val_loss: 0.2337 - val_accuracy: 0.9180\n",
      "Epoch 142/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.9414\n",
      "Epoch 00142: val_accuracy improved from 0.91930 to 0.92790, saving model to /content/drive/My Drive/MyCNN/model-142-0.941420-0.927900.h5'\n",
      "INFO:tensorflow:Assets written to: /content/drive/My Drive/MyCNN/model-142-0.941420-0.927900.h5'/assets\n",
      "391/390 [==============================] - 85s 218ms/step - loss: 0.1653 - accuracy: 0.9414 - val_loss: 0.2083 - val_accuracy: 0.9279\n",
      "Epoch 143/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.9420\n",
      "Epoch 00143: val_accuracy did not improve from 0.92790\n",
      "391/390 [==============================] - 70s 179ms/step - loss: 0.1641 - accuracy: 0.9420 - val_loss: 0.2253 - val_accuracy: 0.9203\n",
      "Epoch 144/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9426\n",
      "Epoch 00144: val_accuracy did not improve from 0.92790\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1620 - accuracy: 0.9426 - val_loss: 0.2483 - val_accuracy: 0.9193\n",
      "Epoch 145/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1692 - accuracy: 0.9405\n",
      "Epoch 00145: val_accuracy did not improve from 0.92790\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1692 - accuracy: 0.9405 - val_loss: 0.2145 - val_accuracy: 0.9261\n",
      "Epoch 146/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1618 - accuracy: 0.9416\n",
      "Epoch 00146: val_accuracy did not improve from 0.92790\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1618 - accuracy: 0.9416 - val_loss: 0.3028 - val_accuracy: 0.8990\n",
      "Epoch 147/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1620 - accuracy: 0.9433\n",
      "Epoch 00147: val_accuracy did not improve from 0.92790\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1620 - accuracy: 0.9433 - val_loss: 0.2521 - val_accuracy: 0.9156\n",
      "Epoch 148/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1625 - accuracy: 0.9423\n",
      "Epoch 00148: val_accuracy did not improve from 0.92790\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1625 - accuracy: 0.9423 - val_loss: 0.2622 - val_accuracy: 0.9145\n",
      "Epoch 149/300\n",
      "391/390 [==============================] - ETA: 0s - loss: 0.1596 - accuracy: 0.9450\n",
      "Epoch 00149: val_accuracy did not improve from 0.92790\n",
      "391/390 [==============================] - 70s 178ms/step - loss: 0.1596 - accuracy: 0.9450 - val_loss: 0.2497 - val_accuracy: 0.9169\n",
      "Epoch 150/300\n",
      " 10/390 [..............................] - ETA: 1:02 - loss: 0.1735 - accuracy: 0.9422Buffered data was truncated after reaching the output size limit."
     ]
    }
   ],
   "source": [
    "          model.fit_generator(\n",
    "            datagen.flow(X_train, y_train, batch_size=128),\n",
    "            steps_per_epoch=(len(X_train)/batch_size),              \n",
    "            epochs=300,\n",
    "            verbose = 1,\n",
    "            validation_data=(X_cv, y_cv),callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hk7J6piKIzTS"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/My Drive/MyCNN/model-142-0.941420-0.927900.h5')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=Adam(),\n",
    "                        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "heZ_DU5jc_7F",
    "outputId": "352c5dee-b9be-4b5c-f854-25b03ed1b5f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2198 - accuracy: 0.9327\n",
      "Test loss: 0.2197745144367218\n",
      "Test accuracy: 0.932699978351593\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6CWkvaUexIj"
   },
   "source": [
    "## RESULT\n",
    "- my intention was to run this till 300 epochs\n",
    "- due to colab time limit I able to train till 150 epochs but still able to achieve the **test accuracy=0.932699978351593**\n",
    "- **Total params: 993,961**\n",
    "\n",
    "#### Hyperparameters\n",
    "- batch_size = 128\n",
    "- num_classes = 10\n",
    "- l = 8\n",
    "- num_filter = 27\n",
    "- compression =1\n",
    "- dropout_rate = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of CNN on CIFR Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
